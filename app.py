import streamlit as st
import re
import pandas as pd
import json
import pytesseract
from PIL import Image, ImageOps, ImageEnhance
import numpy as np

st.set_page_config(page_title="ì—°ì„¸ëŒ€ ì¡¸ì—…ì˜ˆë¹„ì§„ë‹¨", page_icon="ğŸ“", layout="wide")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'ocr_results' not in st.session_state:
    st.session_state.ocr_results = []

# --- 1. ì¡¸ì—…ìš”ê±´ DB ë¡œë“œ ---
@st.cache_data
def load_requirements():
    try:
        with open('requirements.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError: return {}

db = load_requirements()

# --- 2. í—¬í¼ í•¨ìˆ˜ ---

def normalize_string(s):
    if not isinstance(s, str): return ""
    # ë¹„êµë¥¼ ìœ„í•´ ê³µë°± ë° íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€/ì˜ë¬¸/ìˆ«ìë§Œ ë‚¨ê¹€)
    return re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', s).upper()

def classify_course_logic(course_name, year, dept):
    norm_name = normalize_string(course_name)
    if "RC" in norm_name or "ë¦¬ë”ì‹­" in norm_name:
        return "êµì–‘(ë¦¬ë”ì‹­)"
    if year not in db or dept not in db[year]:
        return "êµì–‘/ê¸°íƒ€"
    
    dept_db = db[year][dept]
    known = dept_db.get("known_courses", {})
    
    # ì „ê³µ ì—¬ë¶€ íŒë‹¨ (ì´ë¦„ í¬í•¨ ì—¬ë¶€ë¡œ)
    for req in known.get("major_required", []):
        if normalize_string(req) in norm_name or norm_name in normalize_string(req): return "ì „ê³µí•„ìˆ˜"
    for sel in known.get("major_elective", []):
        if normalize_string(sel) in norm_name or norm_name in normalize_string(sel): return "ì „ê³µì„ íƒ"
    
    for area, courses in db.get("area_courses", {}).items():
        for c in courses:
            if normalize_string(c) in norm_name: return f"êµì–‘({area})"
    return "êµì–‘/ê¸°íƒ€"

def ocr_image_parsing(image_file, year, dept):
    try:
        img = Image.open(image_file).convert('L')
        img = ImageOps.autocontrast(img)
        img = ImageEnhance.Contrast(img).enhance(2.0)
        text = pytesseract.image_to_string(img, lang='kor+eng', config='--psm 6')
        
        parsed_data = []
        for line in text.split('\n'):
            match = re.search(r'^(.*?)\s+(\d+(?:\.\d+)?)(?:\s+.*)?$', line.strip())
            if match:
                raw_name = match.group(1).strip()
                credit = float(match.group(2))
                # í•™ì  ë…¸ì´ì¦ˆ í•„í„°ë§ (10í•™ì  ì´ˆê³¼ ì œì™¸)
                if len(raw_name) < 2 or raw_name.isdigit() or credit > 10: continue
                ftype = classify_course_logic(raw_name, year, dept)
                parsed_data.append({"ê³¼ëª©ëª…": raw_name, "í•™ì ": credit, "ì´ìˆ˜êµ¬ë¶„": ftype})
        return parsed_data
    except: return []

# --- 3. UI êµ¬ì„± ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    years = sorted([k for k in db.keys() if k != "area_courses"]) if db else ["2022"]
    selected_year = st.selectbox("ì…í•™ë…„ë„", years)
    selected_dept = st.selectbox("ì „ê³µ", list(db[selected_year].keys()) if selected_year in db else ["-"])
    if st.button("ğŸ”„ ë°ì´í„° ì´ˆê¸°í™”"):
        st.session_state.ocr_results = []
        st.rerun()

st.title("ğŸ“ ì—°ì„¸ëŒ€ ì¡¸ì—…ìš”ê±´ ì˜ˆë¹„ì§„ë‹¨")
tab1, tab2 = st.tabs(["ğŸ“¸ ì´ë¯¸ì§€ ë¶„ì„", "âœï¸ ê³¼ëª© ìˆ˜ì • ë° ìµœì¢… ì§„ë‹¨"])

with tab1:
    img_files = st.file_uploader("ì„±ì í‘œ ì—…ë¡œë“œ", type=['png','jpg','jpeg'], accept_multiple_files=True)
    if img_files and st.button("ğŸ” ë¶„ì„ ì‹¤í–‰"):
        results = []
        for img in img_files:
            results.extend(ocr_image_parsing(img, selected_year, selected_dept))
        st.session_state.ocr_results = pd.DataFrame(results).drop_duplicates(subset=['ê³¼ëª©ëª…']).to_dict('records')
        st.success("ë¶„ì„ ì™„ë£Œ!")

with tab2:
    df_editor = pd.DataFrame(st.session_state.ocr_results)
    if df_editor.empty: df_editor = pd.DataFrame(columns=["ê³¼ëª©ëª…", "í•™ì ", "ì´ìˆ˜êµ¬ë¶„"])
    edited_df = st.data_editor(df_editor, num_rows="dynamic", use_container_width=True, key="main_editor")
    
    st.divider()
    final_courses = edited_df.to_dict('records')
    
    if final_courses:
        criteria = db[selected_year][selected_dept]
        gen = criteria.get("general_education", {})
        known = criteria.get("known_courses", {})
        
        # [í•µì‹¬] ì‚¬ìš©ì ì§€ì • í‚¤ì›Œë“œ ê¸°ë°˜ ì‹¬í™” íŒì • ë¡œì§
        adv_keywords = [normalize_string(k) for k in known.get("advanced_keywords", [])]

        def is_advanced_match(course_obj):
            c_name_norm = normalize_string(course_obj['ê³¼ëª©ëª…'])
            c_type = str(course_obj['ì´ìˆ˜êµ¬ë¶„'])
            
            # 1. ì „ê³µ(í•„ìˆ˜/ì„ íƒ)ìœ¼ë¡œ ë¶„ë¥˜ëœ ê³¼ëª©ì¸ê°€?
            if "ì „ê³µ" in c_type:
                # 2. ê³¼ëª©ëª…ì— JSON ì‹¬í™” í‚¤ì›Œë“œ(ì„ìƒí™”í•™ ë“±)ê°€ 'í¬í•¨'ë˜ì–´ ìˆëŠ”ê°€?
                # ì˜ˆ: "ì„ìƒí™”í•™ë°ì‹¤í—˜1"ì— "ì„ìƒí™”í•™"ì´ ë“¤ì–´ìˆìœ¼ë¯€ë¡œ True
                if any(kw in c_name_norm for kw in adv_keywords):
                    return True
            return False

        # í•™ì  ì§‘ê³„ (10í•™ì  ì´í•˜ ì •ìƒ ë°ì´í„°ë§Œ)
        total_sum = sum(c['í•™ì '] for c in final_courses if c['í•™ì '] <= 10)
        maj_sum = sum(c['í•™ì '] for c in final_courses if "ì „ê³µ" in str(c['ì´ìˆ˜êµ¬ë¶„']) and c['í•™ì '] <= 10)
        advanced_sum = sum(c['í•™ì '] for c in final_courses if is_advanced_match(c))
        leadership_count = len([c for c in final_courses if "ë¦¬ë”ì‹­" in str(c['ì´ìˆ˜êµ¬ë¶„']) or "RC" in normalize_string(c['ê³¼ëª©ëª…'])])
        
        # ì˜ì—­ ì²´í¬
        passed_areas = set()
        for c in final_courses:
            for area, a_list in db.get("area_courses", {}).items():
                if any(normalize_string(ac) in normalize_string(c['ê³¼ëª©ëª…']) for ac in a_list): passed_areas.add(area)
        missing_areas = sorted(list(set(gen.get("required_areas", [])) - passed_areas))

        # ë¦¬í¬íŠ¸ ì¶œë ¥
        st.header("ğŸ ì¡¸ì—… ìê²© ì˜ˆë¹„ì§„ë‹¨ ë¦¬í¬íŠ¸")
        m1, m2, m3, m4 = st.columns(4)
        m1.metric("ì´ ì·¨ë“í•™ì ", f"{int(total_sum)} / {criteria['total_credits']}")
        m2.metric("ì „ê³µ í•©ê³„", f"{int(maj_sum)} / {criteria['major_total']}")
        m3.metric("3~4000 ë‹¨ìœ„(ì‹¬í™”)", f"{int(advanced_sum)} / {criteria['advanced_course']}", delta=int(advanced_sum - criteria['advanced_course']), delta_color="normal")
        m4.metric("ë¦¬ë”ì‹­(RC)", f"{leadership_count} / 2")

        # ë³´ì™„ ê°€ì´ë“œ
        if not (total_sum >= criteria['total_credits'] and advanced_sum >= criteria['advanced_course'] and not missing_areas):
            st.markdown("### ğŸ’¡ ë¶€ì¡± ìš”ê±´ ë³´ì™„ ê°€ì´ë“œ")
            if advanced_sum < criteria['advanced_course']:
                with st.expander("ğŸ”´ 3000~4000ë‹¨ìœ„(ì‹¬í™”) ì¶”ì²œ ê°•ì˜ ë¦¬ìŠ¤íŠ¸", expanded=True):
                    st.info(f"ì‹¬í™” í•™ì ì´ {int(criteria['advanced_course'] - advanced_sum)}í•™ì  ë¶€ì¡±í•©ë‹ˆë‹¤.")
                    all_majors = known.get('major_required', []) + known.get('major_elective', [])
                    # ë‚´ ì„±ì í‘œì— ì—†ëŠ” ì‹¬í™” ê³¼ëª© í•„í„°ë§
                    my_names = [normalize_string(c['ê³¼ëª©ëª…']) for c in final_courses]
                    not_taken = [m for m in all_majors if any(kw in normalize_string(m) for kw in adv_keywords) 
                                 and not any(normalize_string(m) in n or n in normalize_string(m) for n in my_names)]
                    st.write(", ".join(sorted(list(set(not_taken)))))
            if missing_areas:
                with st.expander("ğŸŸ  ë¶€ì¡±í•œ êµì–‘ ì´ìˆ˜ ì˜ì—­ ì¶”ì²œ ê°•ì˜", expanded=True):
                    for area in missing_areas:
                        st.subheader(f"ğŸ“ {area} ì˜ì—­")
                        st.write(", ".join(db.get("area_courses", {}).get(area, [])))
    else:
        st.info("ì„±ì í‘œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
