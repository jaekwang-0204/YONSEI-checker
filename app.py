import streamlit as st
import re
import pandas as pd
import json
import pytesseract
from PIL import Image, ImageOps, ImageEnhance
import numpy as np

st.set_page_config(page_title="ì—°ì„¸ëŒ€ ì¡¸ì—…ì˜ˆë¹„ì§„ë‹¨", page_icon="ğŸ“", layout="wide")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'ocr_results' not in st.session_state:
    st.session_state.ocr_results = []

# --- 1. ì¡¸ì—…ìš”ê±´ DB ë¡œë“œ ---
@st.cache_data
def load_requirements():
    try:
        with open('requirements.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError: return {}

db = load_requirements()

# --- 2. í—¬í¼ í•¨ìˆ˜ ---

def normalize_string(s):
    if not isinstance(s, str): return ""
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ëŒ€ë¬¸ìí™”
    return re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', s).upper()

@st.dialog("ğŸ› ë²„ê·¸ ì‹ ê³  ë° ë¬¸ì˜")
def show_bug_report_dialog(year, dept):
    st.write("ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë‚˜ìš”? ì•„ë˜ ì •ë³´ë¥¼ ë³µì‚¬í•´ì„œ ë©”ì¼ì„ ë³´ë‚´ì£¼ì„¸ìš”.")
    st.divider()
    st.caption("1. ë°›ëŠ” ì‚¬ëŒ ì´ë©”ì¼")
    st.code("jaekwang1164@gmail.com", language="text")
    st.caption("2. ë©”ì¼ ì œëª©")
    st.code(f"[ì¡¸ì—…ì§„ë‹¨ê¸° ë²„ê·¸ì‹ ê³ ] {year}í•™ë²ˆ {dept}", language="text")
    st.caption("3. ë³¸ë¬¸ ë‚´ìš©")
    st.code("- ì˜¤ë¥˜ í˜„ìƒ:\n- ê¸°ëŒ€ ê²°ê³¼:\n- ì²¨ë¶€íŒŒì¼ ì—¬ë¶€(ì—íƒ€ ìº¡ì³ë³¸ ë“±):", language="text")

def classify_course_logic(course_name, year, dept):
    """[ë¶„ë¥˜ ë¡œì§] RC ìš°ì„  ë° DB í‚¤ì›Œë“œ ë§¤ì¹­"""
    norm_name = normalize_string(course_name)
    
    if "RC" in norm_name or "ë¦¬ë”ì‹­" in norm_name:
        return "êµì–‘(ë¦¬ë”ì‹­)"

    if year not in db or dept not in db[year]:
        return "êµì–‘/ê¸°íƒ€"
    
    dept_db = db[year][dept]
    known = dept_db.get("known_courses", {})
    
    for req in known.get("major_required", []):
        if normalize_string(req) in norm_name: return "ì „ê³µí•„ìˆ˜"
    for sel in known.get("major_elective", []):
        if normalize_string(sel) in norm_name: return "ì „ê³µì„ íƒ"
            
    for area, courses in db.get("area_courses", {}).items():
        for c in courses:
            if normalize_string(c) in norm_name: return f"êµì–‘({area})"
                
    return "êµì–‘/ê¸°íƒ€"

def ocr_image_parsing(image_file, year, dept):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° OCR íŒŒì‹±"""
    try:
        img = Image.open(image_file).convert('L')
        img = ImageOps.autocontrast(img)
        img = ImageEnhance.Contrast(img).enhance(2.0)
        text = pytesseract.image_to_string(img, lang='kor+eng', config='--psm 6')
        
        parsed_data = []
        for line in text.split('\n'):
            match = re.search(r'^(.*?)\s+(\d+(?:\.\d+)?)(?:\s+.*)?$', line.strip())
            if match:
                raw_name = match.group(1).strip()
                credit = float(match.group(2))
                # í•™ì ì´ 10ì ì„ ë„˜ìœ¼ë©´(í•™ë²ˆ ë“±) ë…¸ì´ì¦ˆë¡œ ê°„ì£¼í•˜ì—¬ ì œì™¸
                if len(raw_name) < 2 or raw_name.isdigit() or credit > 10: continue
                ftype = classify_course_logic(raw_name, year, dept)
                parsed_data.append({"ê³¼ëª©ëª…": raw_name, "í•™ì ": credit, "ì´ìˆ˜êµ¬ë¶„": ftype})
        return parsed_data
    except: return []

# --- 3. ì‚¬ì´ë“œë°” êµ¬ì„± ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    years = sorted([k for k in db.keys() if k != "area_courses"]) if db else ["2022"]
    selected_year = st.selectbox("ì…í•™ë…„ë„", years)
    selected_dept = st.selectbox("ì „ê³µ", list(db[selected_year].keys()) if selected_year in db else ["-"])
    
    st.divider()
    if st.button("ğŸ”„ ëª¨ë“  ë°ì´í„° ì´ˆê¸°í™”"):
        st.session_state.ocr_results = []
        st.rerun()
    
    if st.button("ğŸ› ë²„ê·¸ ì‹ ê³ "):
        show_bug_report_dialog(selected_year, selected_dept)

# --- 4. ë©”ì¸ UI ---
st.title("ğŸ“ ì—°ì„¸ëŒ€ ì¡¸ì—…ìš”ê±´ ì˜ˆë¹„ì§„ë‹¨")
st.info("ì—ë¸Œë¦¬íƒ€ì„ ì„±ì  í™”ë©´(í•™ì ê³„ì‚°ê¸°) ìº¡ì³ë³¸ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”. ì—¬ëŸ¬ ì¥ ì—…ë¡œë“œ ì‹œ ëª¨ë“  í•™ê¸°ë¥¼ í†µí•© ë¶„ì„í•©ë‹ˆë‹¤.")

tab1, tab2 = st.tabs(["ğŸ“¸ ì´ë¯¸ì§€ ë¶„ì„", "âœï¸ ê³¼ëª© ìˆ˜ì • ë° ìµœì¢… ì§„ë‹¨"])

with tab1:
    img_files = st.file_uploader("ì—ë¸Œë¦¬íƒ€ì„ ì„±ì  ìº¡ì³ (PNG, JPG)", type=['png','jpg','jpeg'], accept_multiple_files=True)
    if img_files and st.button("ğŸ” ì„±ì í‘œ ë¶„ì„ ì‹¤í–‰"):
        with st.spinner("ì´ë¯¸ì§€ì—ì„œ ìˆ˜ê°• ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘..."):
            all_results = []
            for img in img_files:
                all_results.extend(ocr_image_parsing(img, selected_year, selected_dept))
            
            df_temp = pd.DataFrame(all_results).drop_duplicates(subset=['ê³¼ëª©ëª…'])
            st.session_state.ocr_results = df_temp.to_dict('records')
            st.success(f"ì´ {len(st.session_state.ocr_results)}ê°œì˜ ê³¼ëª©ì„ ì¸ì‹í–ˆìŠµë‹ˆë‹¤.")

with tab2:
    st.markdown("### ğŸ“ ìˆ˜ê°• ê³¼ëª© ê´€ë¦¬")
    st.caption("OCR ì¸ì‹ ê²°ê³¼ê°€ í‹€ë ¸ë‹¤ë©´ ì§ì ‘ ìˆ˜ì •í•˜ì„¸ìš”. ì´ìˆ˜êµ¬ë¶„ì´ 'ì „ê³µ'ìœ¼ë¡œ ë˜ì–´ì•¼ ì‹¬í™” í•™ì ì— ì§‘ê³„ë©ë‹ˆë‹¤.")
    
    df_editor = pd.DataFrame(st.session_state.ocr_results)
    if df_editor.empty:
        df_editor = pd.DataFrame(columns=["ê³¼ëª©ëª…", "í•™ì ", "ì´ìˆ˜êµ¬ë¶„"])

    edited_df = st.data_editor(
        df_editor, num_rows="dynamic", use_container_width=True,
        column_config={
            "í•™ì ": st.column_config.NumberColumn("í•™ì ", step=0.5, format="%.1f"),
            "ì´ìˆ˜êµ¬ë¶„": st.column_config.SelectboxColumn("ì´ìˆ˜êµ¬ë¶„", options=[
                "ì „ê³µí•„ìˆ˜", "ì „ê³µì„ íƒ", "êµì–‘(ë¦¬ë”ì‹­)", "êµì–‘(ë¬¸í•™ê³¼ì˜ˆìˆ )", "êµì–‘(ì¸ê°„ê³¼ì—­ì‚¬)", 
                "êµì–‘(ì–¸ì–´ì™€í‘œí˜„)", "êµì–‘(ê°€ì¹˜ì™€ìœ¤ë¦¬)", "êµì–‘(êµ­ê°€ì™€ì‚¬íšŒ)", "êµì–‘(ì§€ì—­ê³¼ì„¸ê³„)", 
                "êµì–‘(ë…¼ë¦¬ì™€ìˆ˜ë¦¬)", "êµì–‘(ìì—°ê³¼ìš°ì£¼)", "êµì–‘(ìƒëª…ê³¼í™˜ê²½)", "êµì–‘(ì •ë³´ì™€ê¸°ìˆ )", 
                "êµì–‘(ì²´ìœ¡ê³¼ê±´ê°•)", "êµì–‘/ê¸°íƒ€"
            ])
        }, key="main_editor"
    )

    # --- 5. ìµœì¢… ë¶„ì„ ê²°ê³¼ í‘œì‹œ ë° ë³´ì™„ ê°€ì´ë“œ ---
    st.divider()
    final_courses = edited_df.to_dict('records')
    
    if final_courses:
        criteria = db[selected_year][selected_dept]
        gen = criteria.get("general_education", {})
        known = criteria.get("known_courses", {})
        
        # JSON ë°ì´í„° í™•ë³´
        all_major_list = known.get('major_required', []) + known.get('major_elective', [])
        adv_patterns = known.get("advanced_keywords", [])

        # [í•µì‹¬] ìœ ì—°í•œ ì‹¬í™” í•™ì  íŒì • í•¨ìˆ˜ (ì•ê¸€ì 4ì ë§¤ì¹­)
        def get_advanced_score_flexible(course):
            c_name_norm = normalize_string(str(course['ê³¼ëª©ëª…']))
            c_type = str(course['ì´ìˆ˜êµ¬ë¶„'])
            c_credit = float(course['í•™ì '])
            
            # í•™ì ì´ ë¹„ì •ìƒì ì´ë©´ ì œì™¸
            if c_credit > 10: return 0
            
            if "ì „ê³µ" in c_type:
                # 1. ê³¼ëª©ëª…ì— ì§ì ‘ ì‹¬í™” í‚¤ì›Œë“œ(BML3 ë“±)ê°€ í¬í•¨ëœ ê²½ìš°
                if any(kw in c_name_norm for kw in adv_patterns):
                    return c_credit
                
                # 2. JSON ì „ê³µ ë¦¬ìŠ¤íŠ¸ì™€ ì• 4ê¸€ì ë§¤ì¹­
                for major_name in all_major_list:
                    major_norm = normalize_string(major_name)
                    # JSONìƒì˜ ê³¼ëª©ì´ ì‹¬í™” ê³¼ëª©ì¸ì§€ í™•ì¸ í›„, ì• 4ê¸€ì ì¼ì¹˜ ì—¬ë¶€ íŒì •
                    if any(kw in major_norm for kw in adv_patterns):
                        if (len(major_norm) >= 4 and major_norm[:4] in c_name_norm) or (major_norm in c_name_norm):
                            return c_credit
            return 0

        # í•™ì  í•©ê³„ (í•„í„°ë§ ì ìš©)
        total_sum = sum(c['í•™ì '] for c in final_courses if c['í•™ì '] <= 10)
        maj_total_sum = sum(c['í•™ì '] for c in final_courses if "ì „ê³µ" in str(c['ì´ìˆ˜êµ¬ë¶„']) and c['í•™ì '] <= 10)
        advanced_sum = sum(get_advanced_score_flexible(c) for c in final_courses)
        
        # ë¦¬ë”ì‹­ ë° ì˜ì—­ ë¶„ì„
        leadership_count = len([c for c in final_courses if "ë¦¬ë”ì‹­" in str(c['ì´ìˆ˜êµ¬ë¶„']) or "RC" in normalize_string(str(c['ê³¼ëª©ëª…']))])
        
        passed_areas = set()
        for course in final_courses:
            course_norm = normalize_string(str(course['ê³¼ëª©ëª…']))
            for area, area_course_list in db.get("area_courses", {}).items():
                if any(normalize_string(ac) in course_norm for ac in area_course_list):
                    passed_areas.add(area)
        
        missing_areas = sorted(list(set(gen.get("required_areas", [])) - passed_areas))

        # ìµœì¢… íŒì •
        is_all_pass = all([total_sum >= criteria['total_credits'], advanced_sum >= criteria['advanced_course'], not missing_areas])

        st.header("ğŸ ì¡¸ì—… ìê²© ì˜ˆë¹„ì§„ë‹¨ ë¦¬í¬íŠ¸")
        if is_all_pass: st.success("ğŸ‰ ëª¨ë“  ì¡¸ì—… ìš”ê±´ì„ ì¶©ì¡±í–ˆìŠµë‹ˆë‹¤."); st.balloons()
        else: st.error("âš ï¸ ì•„ì§ ì¶©ì¡±ë˜ì§€ ì•Šì€ ìš”ê±´ì´ ìˆìŠµë‹ˆë‹¤.")

        # ëŒ€ì‹œë³´ë“œ (4ì—´)
        m1, m2, m3, m4 = st.columns(4)
        m1.metric("ì´ ì·¨ë“í•™ì ", f"{int(total_sum)} / {criteria['total_credits']}", delta=int(total_sum - criteria['total_credits']))
        m2.metric("ì „ê³µ í•©ê³„", f"{int(maj_total_sum)} / {criteria['major_total']}")
        m3.metric("3~4000 ë‹¨ìœ„(ì‹¬í™”)", f"{int(advanced_sum)} / {criteria['advanced_course']}", delta=int(advanced_sum - criteria['advanced_course']), delta_color="normal")
        m4.metric("ë¦¬ë”ì‹­(RC)", f"{leadership_count} / 2")

        

        # ë³´ì™„ ê°€ì´ë“œ
        if not is_all_pass:
            st.markdown("### ğŸ’¡ ë¶€ì¡± ìš”ê±´ ë³´ì™„ ê°€ì´ë“œ")
            if advanced_sum < criteria['advanced_course']:
                with st.expander("ğŸ”´ 3000~4000ë‹¨ìœ„(ì‹¬í™”) ì¶”ì²œ ê°•ì˜ ë¦¬ìŠ¤íŠ¸", expanded=True):
                    st.info(f"ì‹¬í™” í•™ì ì´ {int(criteria['advanced_course'] - advanced_sum)}í•™ì  ë¶€ì¡±í•©ë‹ˆë‹¤.")
                    adv_candidates = [m for m in all_major_list if any(kw in normalize_string(m) for kw in adv_patterns)]
                    my_norms = [normalize_string(c['ê³¼ëª©ëª…']) for c in final_courses]
                    not_taken = [m for m in adv_candidates if not any(normalize_string(m)[:4] in n for n in my_norms)]
                    st.write(", ".join(sorted(list(set(not_taken)))))

            if missing_areas:
                with st.expander("ğŸŸ  ë¶€ì¡±í•œ êµì–‘ ì´ìˆ˜ ì˜ì—­ ì¶”ì²œ ê°•ì˜", expanded=True):
                    for area in missing_areas:
                        st.subheader(f"ğŸ“ {area} ì˜ì—­")
                        st.write(", ".join(db.get("area_courses", {}).get(area, [])))
            
        with st.expander("ğŸ“Š ìˆ˜ê°• ê³¼ëª© ìƒì„¸ í†µê³„"):
            st.dataframe(pd.DataFrame(final_courses), use_container_width=True)
    else:
        st.info("ì„±ì í‘œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
