import streamlit as st
import pdfplumber
import re
import pandas as pd
import json
import pytesseract
from PIL import Image, ImageOps, ImageEnhance
import numpy as np
import difflib # [NEW] ìœ ì‚¬ë„ ê²€ì‚¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

# Tesseract ê²½ë¡œ (í•„ìš”ì‹œ ì„¤ì •, ë¦¬ëˆ…ìŠ¤/í´ë¼ìš°ë“œ í™˜ê²½ì€ ì£¼ì„ ìœ ì§€)
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

st.set_page_config(page_title="ì¡¸ì—…ìš”ê±´ ì§„ë‹¨ê¸° (Ultimate)", page_icon="ğŸ“")

# --- ì„¸ì…˜ ìƒíƒœ ---
if 'manual_courses' not in st.session_state:
    st.session_state.manual_courses = []

# --- 1. DB ë¡œë“œ ---
@st.cache_data
def load_requirements():
    try:
        with open('requirements.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

db = load_requirements()

# --- 2. í…ìŠ¤íŠ¸ ì²˜ë¦¬ í—¬í¼ í•¨ìˆ˜ ---

def normalize_string(s):
    """ë¹„êµë¥¼ ìœ„í•´ í•œê¸€/ì˜ì–´/ìˆ«ìë§Œ ë‚¨ê¸°ê³  ê³µë°± ë“± ì œê±°"""
    if not isinstance(s, str): return ""
    return re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', s)

def clean_ocr_line(line):
    """OCR ê²°ê³¼ ë¼ì¸ë³„ ë…¸ì´ì¦ˆ ì •ë¦¬"""
    # ë¬¼ê²°í‘œ(~), íŠ¹ìˆ˜ë¬¸ì ì œê±° (ê´„í˜¸ëŠ” ì‚´ë¦¼)
    line = re.sub(r'[~@#$%\^&*_\-=|;:"<>,.?/]', ' ', line)
    return line.strip()

def classify_course_fuzzy(course_name, year, dept):
    """
    [NEW] ìœ ì‚¬ë„ ê²€ì‚¬ ê¸°ë°˜ ê³¼ëª© ë¶„ë¥˜
    OCRëœ ì´ë¦„ê³¼ DBì˜ ì „ê³µ ê³¼ëª©ëª…ì„ ë¹„êµí•˜ì—¬ ê°€ì¥ ë¹„ìŠ·í•œ ê²ƒì„ ì°¾ìŒ
    """
    if year not in db or dept not in db[year]:
        return course_name, "êµì–‘/ê¸°íƒ€"
    
    known = db[year][dept].get("known_courses", {})
    norm_input = normalize_string(course_name)
    
    # 1. DB ëª©ë¡ ì¤€ë¹„
    # (ê³¼ëª©ëª…, íƒ€ì…) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    db_courses = []
    for req in known.get("major_required", []):
        db_courses.append((req, "ì „ê³µí•„ìˆ˜"))
    for sel in known.get("major_elective", []):
        db_courses.append((sel, "ì „ê³µì„ íƒ"))
        
    best_match = None
    highest_ratio = 0.0
    
    for db_name, db_type in db_courses:
        norm_db = normalize_string(db_name)
        
        # (A) ì™„ì „ í¬í•¨ ê´€ê³„ (ê°€ì¥ ê°•ë ¥)
        if norm_db in norm_input or norm_input in norm_db:
            return db_name, db_type # ì •í™•í•œ DB ëª…ì¹­ìœ¼ë¡œ ë°˜í™˜
            
        # (B) ìœ ì‚¬ë„ ê²€ì‚¬ (ì˜¤íƒ€ ë³´ì •)
        ratio = difflib.SequenceMatcher(None, norm_db, norm_input).ratio()
        if ratio > highest_ratio:
            highest_ratio = ratio
            best_match = (db_name, db_type)
            
    # ìœ ì‚¬ë„ê°€ 0.6 (60%) ì´ìƒì´ë©´ ê°™ì€ ê³¼ëª©ìœ¼ë¡œ ì¸ì •
    if best_match and highest_ratio >= 0.6:
        return best_match[0], best_match[1]
        
    return course_name, "êµì–‘/ê¸°íƒ€"

def ocr_image_and_parse(image_file, year, dept):
    try:
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        img = Image.open(image_file).convert('L')
        img = ImageOps.autocontrast(img)
        img = ImageEnhance.Contrast(img).enhance(2.0)
        
        # OCR ì‹¤í–‰
        text = pytesseract.image_to_string(img, lang='kor+eng', config='--psm 6')
        
        parsed_courses = []
        lines = text.split('\n')
        
        # [NEW] í—¤ë” ê°ì§€ í”Œë˜ê·¸ (ì´ê²Œ Trueê°€ ë˜ê¸° ì „ì—” íŒŒì‹± ì•ˆí•¨)
        start_parsing = False
        
        for line in lines:
            clean_line = clean_ocr_line(line)
            if not clean_line: continue
            
            # 1. í—¤ë” ê°ì§€ ë¡œì§ (ê³¼ëª©ëª…, í•™ì , ì„±ì  ë“±ì˜ ë‹¨ì–´ê°€ ë³´ì´ë©´ ì‹œì‘)
            if not start_parsing:
                if any(k in clean_line for k in ["ê³¼ëª©ëª…", "í•™ì ", "ì„±ì ", "ì „ê³µ", "ì´ìˆ˜", "ë“±ê¸‰"]):
                    start_parsing = True
                continue # í—¤ë” ì¤„ ìì²´ëŠ” ê±´ë„ˆëœ€
            
            # 2. íŒŒì‹± ë¡œì§ (í—¤ë” ì´í›„ë¶€í„° ë™ì‘)
            
            # ë…¸ì´ì¦ˆ í•„í„° (í—¤ë” ì´í›„ì—ë„ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ì´ìƒí•œ ì¤„ ì œê±°)
            if any(k in clean_line for k in ["í‰ì ", "ì·¨ë“", "ì´ì ", "í•™ë…„", "í•™ê¸°", "ì‹ ì²­"]):
                continue
                
            # íŒ¨í„´: (ê³¼ëª©ëª…) ... (í•™ì :ìˆ«ì)
            # ì˜ˆ: "ë¯¸ë˜ì„¤ê³„ë¦¬ë¹™ë© 3 P" -> Name="ë¯¸ë˜ì„¤ê³„ë¦¬ë¹™ë©", Credit=3
            match = re.search(r'^(.*?)\s+([1-9](?:\.5)?)(?:\s+.*)?$', clean_line)
            
            if match:
                raw_name = match.group(1).strip()
                credit = float(match.group(2))
                
                # ê³¼ëª©ëª… ìœ íš¨ì„± ê²€ì‚¬
                if len(raw_name) < 2 or raw_name in ["0", "O", "o"]: continue
                # í•œê¸€/ì˜ì–´ê°€ ì—†ëŠ” íŠ¹ìˆ˜ë¬¸ì ì¤„ ì œê±°
                if not re.search(r'[ê°€-í£a-zA-Z]', raw_name): continue

                # [NEW] ìœ ì‚¬ë„ ê¸°ë°˜ ë¶„ë¥˜ ì‹¤í–‰
                final_name, final_type = classify_course_fuzzy(raw_name, year, dept)
                
                if not any(c['name'] == final_name for c in parsed_courses):
                    parsed_courses.append({
                        "name": final_name, "credit": credit, "type": final_type
                    })
                    
        return text, parsed_courses
        
    except Exception as e:
        return f"Error: {e}", []

def filter_failed_courses(full_text):
    lines = full_text.split('\n')
    filtered = []
    for line in lines:
        if re.search(r'\sF\s|\sF$|\sNP\s|\sNP$', line): continue
        filtered.append(line)
    return "\n".join(filtered)

@st.dialog("ğŸ› ë²„ê·¸ ì‹ ê³ ")
def show_bug_report_dialog(year, dept):
    st.write("ì˜¤ë¥˜ ë‚´ìš©ì„ ë³µì‚¬í•´ì„œ ë©”ì¼ì„ ë³´ë‚´ì£¼ì„¸ìš”.")
    st.code(f"ë°›ëŠ”ì‚¬ëŒ: jaekwang1164@gmail.com\nì œëª©: [ë²„ê·¸] {year} {dept}", language="text")


# --- UI êµ¬ì„± ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    if db:
        years = sorted([k for k in db.keys() if k != "area_courses"])
    else:
        years = ["2022"]
    selected_year = st.selectbox("ì…í•™ë…„ë„", years)
    
    if selected_year in db:
        depts = list(db[selected_year].keys())
        selected_dept = st.selectbox("ì „ê³µ", depts)
    else:
        selected_dept = st.selectbox("ì „ê³µ", ["-"])

    st.divider()
    
    st.markdown("### â• ê³¼ëª© ìˆ˜ë™ ì¶”ê°€")
    with st.form("add_form", clear_on_submit=True):
        m_name = st.text_input("ê³¼ëª©ëª…")
        m_credit = st.number_input("í•™ì ", 0.5, 10.0, 3.0, 0.5)
        m_type_sel = st.selectbox("êµ¬ë¶„", ["ìë™ê°ì§€", "ì „ê³µí•„ìˆ˜", "ì „ê³µì„ íƒ", "êµì–‘/ê¸°íƒ€"])
        if st.form_submit_button("ì¶”ê°€"):
            if m_type_sel == "ìë™ê°ì§€":
                _, ftype = classify_course_fuzzy(m_name, selected_year, selected_dept)
            else:
                ftype = m_type_sel
            
            st.session_state.manual_courses.append({
                "name": m_name, "credit": m_credit, "type": ftype
            })
            st.success(f"{m_name} ì¶”ê°€ë¨")
            
    if st.session_state.manual_courses:
        st.markdown("---")
        for i, c in enumerate(st.session_state.manual_courses):
            c1, c2 = st.columns([4,1])
            c1.text(f"{c['name']} ({c['type']})")
            if c2.button("x", key=f"d{i}"):
                del st.session_state.manual_courses[i]
                st.rerun()
    
    st.divider()
    if st.button("ğŸ“§ ì˜¤ë¥˜ ì‹ ê³ "): show_bug_report_dialog(selected_year, selected_dept)


# --- ë©”ì¸ ---
st.title("ğŸ“ ì—°ì„¸ëŒ€ ì¡¸ì—…ìš”ê±´ ì§„ë‹¨ê¸°")
st.caption(f"ê¸°ì¤€: {selected_year}í•™ë²ˆ {selected_dept}")

c1, c2 = st.columns(2)
is_eng = c1.checkbox("ì™¸êµ­ì–´ ì¸ì¦", False)
is_info = c2.checkbox("ì •ë³´ ì¸ì¦", False)

st.divider()

tab1, tab2, tab3 = st.tabs(["ğŸ“„ PDF", "ğŸ“¸ ìº¡ì³/ì´ë¯¸ì§€", "âŒ¨ï¸ í…ìŠ¤íŠ¸"])
extracted_text = ""
ocr_courses = []

with tab1:
    pdf_file = st.file_uploader("ì„±ì ì¦ëª…ì„œ PDF", type="pdf")
    if pdf_file:
        with pdfplumber.open(pdf_file) as pdf:
            for p in pdf.pages: extracted_text += (p.extract_text() or "") + "\n"

with tab2:
    st.info("ì—ë¸Œë¦¬íƒ€ì„, í¬í„¸ ìº¡ì³ (ì—¬ëŸ¬ ì¥ ê°€ëŠ¥, í‘ë°± ìë™ë³´ì •)")
    img_files = st.file_uploader("ì´ë¯¸ì§€", type=['png','jpg'], accept_multiple_files=True)
    if img_files:
        with st.spinner("ì´ë¯¸ì§€ ì •ë°€ ë¶„ì„ ì¤‘..."):
            for img in img_files:
                txt, parsed = ocr_image_and_parse(img, selected_year, selected_dept)
                extracted_text += txt + "\n"
                ocr_courses.extend(parsed)

with tab3:
    txt_in = st.text_area("í…ìŠ¤íŠ¸ ì…ë ¥")
    if txt_in: extracted_text += txt_in

# --- ë¶„ì„ ---
manual_txt = "\n".join([c['name'] for c in st.session_state.manual_courses])
full_text = extracted_text + "\n" + manual_txt

if full_text.strip():
    if selected_year not in db: st.stop()
    criteria = db[selected_year][selected_dept]
    gen_rule = criteria.get("general_education", {})
    clean_text = filter_failed_courses(full_text)
    
    # 1. í•™ì  ê³„ì‚°
    # (A) PDFì—ì„œ ì´ì  ì°¾ê¸° (ê°€ì¥ ì •í™•)
    pdf_total = float((re.search(r'(?:ì·¨ë“í•™ì |í•™ì ê³„)[:\s]*(\d{2,3})', clean_text) or [0,0])[1])
    pdf_maj_req = float((re.search(r'ì „ê³µí•„ìˆ˜[:\s]*(\d{1,3})', clean_text) or [0,0])[1])
    pdf_maj_sel = float((re.search(r'ì „ê³µì„ íƒ[:\s]*(\d{1,3})', clean_text) or [0,0])[1])
    pdf_upper = float((re.search(r'3~4ì²œë‹¨ìœ„[:\s]*(\d{1,3})', clean_text) or [0,0])[1])
    
    # (B) OCR/ìˆ˜ë™ í•©ì‚°
    all_added = st.session_state.manual_courses + ocr_courses
    # ì¤‘ë³µ ì œê±° (ê³¼ëª©ëª… ê¸°ì¤€)
    unique_added = {v['name']:v for v in all_added}.values()
    
    added_total = sum(c['credit'] for c in unique_added)
    added_req = sum(c['credit'] for c in unique_added if c['type'] == 'ì „ê³µí•„ìˆ˜')
    added_sel = sum(c['credit'] for c in unique_added if c['type'] == 'ì „ê³µì„ íƒ')
    
    # (C) ìµœì¢… ê²°ì •
    if pdf_total > 0:
        # PDF ìš°ì„ 
        final_total = pdf_total + sum(c['credit'] for c in st.session_state.manual_courses)
        final_req = pdf_maj_req + sum(c['credit'] for c in st.session_state.manual_courses if c['type'] == 'ì „ê³µí•„ìˆ˜')
        final_sel = pdf_maj_sel + sum(c['credit'] for c in st.session_state.manual_courses if c['type'] == 'ì „ê³µì„ íƒ')
    else:
        # ì´ë¯¸ì§€ ëª¨ë“œ
        final_total = added_total
        final_req = added_req
        final_sel = added_sel
    
    final_maj = final_req + final_sel

    # 2. êµì–‘ ì²´í¬
    req_fail = []
    for item in gen_rule.get("required_courses", []):
        # í…ìŠ¤íŠ¸ ê²€ìƒ‰
        found_in_text = any(kw in clean_text for kw in item["keywords"])
        
        # ë¦¬ìŠ¤íŠ¸ ê²€ìƒ‰ (ìœ ì‚¬ë„ ê²€ì‚¬ í†µê³¼í•œ ëª…ì¹­ ê¸°ì¤€)
        found_in_list = False
        if not found_in_text:
            for course in unique_added:
                # OCR ê³¼ì •ì—ì„œ ì´ë¯¸ DB ë§¤ì¹­ë˜ì–´ 'ì •í™•í•œ ëª…ì¹­'ìœ¼ë¡œ ë³€í™˜ëœ ìƒíƒœì¼ ìˆ˜ ìˆìŒ
                norm_name = normalize_string(course['name'])
                if any(kw in norm_name for kw in item["keywords"]):
                    found_in_list = True
                    break
        
        if not found_in_text and not found_in_list:
            req_fail.append(item['name'])

    all_area = set(gen_rule.get("required_areas", []) + gen_rule.get("elective_areas", []))
    my_area = [a for a in all_area if a in clean_text]
    
    miss_req_area = set(gen_rule.get("required_areas", [])) - set(my_area)
    elec_fail_cnt = max(0, gen_rule["elective_min_count"] - len([a for a in my_area if a in gen_rule.get("elective_areas", [])]))

    # 3. íŒì •
    final_pass = all([
        final_total >= criteria['total_credits'],
        final_maj >= criteria['major_total'],
        final_req >= criteria['major_required'],
        (pdf_upper >= criteria['advanced_course'] if pdf_total > 0 else True), 
        not req_fail, not miss_req_area, elec_fail_cnt == 0,
        is_eng, is_info
    ])
    
    st.divider()
    if final_pass: st.balloons(); st.success("ì¡¸ì—… ê°€ëŠ¥!")
    else: st.error("ì¡¸ì—… ìš”ê±´ ë¶€ì¡±")
    
    c1, c2, c3 = st.columns(3)
    c1.metric("ì´ í•™ì ", f"{int(final_total)}/{criteria['total_credits']}")
    c2.metric("ì „ê³µ(í•„+ì„ )", f"{int(final_maj)}/{criteria['major_total']}")
    c3.metric("ì „ê³µí•„ìˆ˜", f"{int(final_req)}/{criteria['major_required']}")
    
    if not final_pass:
        st.subheader("ğŸ› ï¸ ë³´ì™„ í•„ìš”")
        if final_total < criteria['total_credits']: st.warning(f"ì´ì  {int(criteria['total_credits']-final_total)} ë¶€ì¡±")
        if final_req < criteria['major_required']: st.warning(f"ì „í•„ {int(criteria['major_required']-final_req)} ë¶€ì¡±")
        if req_fail: st.error(f"í•„ìˆ˜êµì–‘ ë¯¸ì´ìˆ˜: {', '.join(req_fail)}")
        if miss_req_area: st.error(f"í•„ìˆ˜ì˜ì—­ ë¯¸ì´ìˆ˜: {', '.join(miss_req_area)}")
        if elec_fail_cnt: 
            st.error(f"ì„ íƒì˜ì—­ {elec_fail_cnt}ê°œ ë¶€ì¡±")
            with st.expander("ì¶”ì²œ ê°•ì˜"):
                rmap = gen_rule.get("area_courses", {}) or db.get("area_courses", {})
                for a in (set(gen_rule.get("elective_areas", [])) - set(my_area)):
                    st.write(f"**[{a}]**", ", ".join(rmap.get(a, [])))

    with st.expander("ğŸ“¸ ì¸ì‹ëœ ê³¼ëª© ëª©ë¡ (í´ë¦­)"):
        if ocr_courses:
            df = pd.DataFrame(ocr_courses)
            df = df.drop_duplicates(subset=['name'])
            st.dataframe(df)
            st.caption(f"ì´ë¯¸ì§€ ì¸ì‹ í•™ì  í•©ê³„: {added_total}ì ")
        else:
            st.info("ì´ë¯¸ì§€ì—ì„œ ì¸ì‹ëœ ê³¼ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            
    with st.expander("ğŸ“„ ì „ì²´ í…ìŠ¤íŠ¸"):
        st.text(clean_text)

else:
    st.info("ì„±ì í‘œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
