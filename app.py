import streamlit as st
import re
import pandas as pd
import json
import pytesseract
from PIL import Image, ImageOps, ImageEnhance
import numpy as np

st.set_page_config(page_title="ì—°ì„¸ëŒ€ ì¡¸ì—…ì˜ˆë¹„ì§„ë‹¨", page_icon="ğŸ“", layout="wide")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'ocr_results' not in st.session_state:
    st.session_state.ocr_results = []

# --- 1. ì¡¸ì—…ìš”ê±´ DB ë¡œë“œ ---
@st.cache_data
def load_requirements():
    try:
        with open('requirements.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError: return {}

db = load_requirements()

# --- 2. í—¬í¼ í•¨ìˆ˜ ---

def normalize_string(s):
    if not isinstance(s, str): return ""
    return re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', s).upper()

@st.dialog("ğŸ› ë²„ê·¸ ì‹ ê³  ë° ë¬¸ì˜")
def show_bug_report_dialog(year, dept):
    st.write("ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë‚˜ìš”? ì•„ë˜ ì •ë³´ë¥¼ ë³µì‚¬í•´ì„œ ë©”ì¼ì„ ë³´ë‚´ì£¼ì„¸ìš”.")
    st.divider()
    st.caption("1. ë°›ëŠ” ì‚¬ëŒ ì´ë©”ì¼")
    st.code("jaekwang1164@gmail.com", language="text")
    st.caption("2. ë©”ì¼ ì œëª©")
    st.code(f"[ì¡¸ì—…ì§„ë‹¨ê¸° ë²„ê·¸ì‹ ê³ ] {year}í•™ë²ˆ {dept}", language="text")
    st.caption("3. ë³¸ë¬¸ ë‚´ìš©")
    st.code("- ì˜¤ë¥˜ í˜„ìƒ:\n- ê¸°ëŒ€ ê²°ê³¼:\n- ì²¨ë¶€íŒŒì¼ ì—¬ë¶€(ì—íƒ€ ìº¡ì³ë³¸ ë“±):", language="text")

def classify_course_logic(course_name, year, version, dept):
    norm_name = normalize_string(course_name)

    # 1. RC/ë¦¬ë”ì‹­ ì˜ˆì™¸ ì²˜ë¦¬
    if "RC" in norm_name or "ë¦¬ë”ì‹­" in norm_name:
        return "êµì–‘(ë¦¬ë”ì‹­)"

    try:
        dept_db = db[year][version][dept]
    except KeyError:
        return "êµì–‘/ê¸°íƒ€"

    known = dept_db.get("known_courses", {})

    # [ê°œì„ ] 2. ì „ê³µ í•„ìˆ˜ ì²´í¬
    for req in known.get("major_required", []):
        if normalize_string(req) in norm_name: 
            return "ì „ê³µí•„ìˆ˜"

    # [ê°œì„ ] 3. ì „ê³µ ì„ íƒ ì²´í¬ (ì„ìƒì‹¤ìŠµ í‚¤ì›Œë“œ ê°•í™”)
    major_sel_list = known.get("major_elective", [])
    for sel in major_sel_list:
        if normalize_string(sel) in norm_name: 
            return "ì „ê³µì„ íƒ"
    
    # [ì¶”ê°€] 4. íŠ¹ì • í‚¤ì›Œë“œ ê°•ì œ ë§¤ì¹­ (ë³´ì¡° ì¥ì¹˜)
    if "ì„ìƒì‹¤ìŠµ" in norm_name or "ì„ìƒë³‘ë¦¬ì‚¬" in norm_name:
        return "ì „ê³µì„ íƒ"

    # 5. êµì–‘ ì˜ì—­ ì²´í¬ (ê¸°ì¡´ê³¼ ë™ì¼)
    # ...
    return "êµì–‘/ê¸°íƒ€"

def ocr_image_parsing(image_file, year, version, dept):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° OCR íŒŒì‹±"""
    try:
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì´ì§„í™”
        img = Image.open(image_file).convert('L')

        # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•: 1500px
        if img.width > 1500:
            ratio = 1500 / float(img.width)
            new_height = int(float(img.height) * ratio)
            img = img.resize((1500, new_height), Image.Resampling.LANCZOS)

        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        img = ImageEnhance.Sharpness(img).enhance(2.0) #ì„ ëª…ë„ ìƒí–¥
        img = ImageOps.autocontrast(img)
        img = ImageEnhance.Contrast(img).enhance(2.5) #ëŒ€ë¹„ ìƒí–¥

        # OCR ì„¤ì • ìµœì í™”
        # [ìµœì í™”] ì¸ì‹ ë²”ìœ„ë¥¼ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ë¡œ ì œí•œí•˜ì—¬ ì†ë„ í–¥ìƒ
        custom_config = '--psm 6 --oem 3'
        text = pytesseract.image_to_string(img, lang='kor+eng', config=custom_config)

        parsed_data = []
        for line in text.split('\n'):
            # íŒ¨í„´: (ê°•ì˜ëª…) (í•™ì ) ìˆœì„œ
            match = re.search(r'^(.*?)\s+(\d+(?:\.\d+)?)(?:\s+.*)?$', line.strip())
            if match:
                raw_name = match.group(1).strip()
                credit = float(match.group(2))

                # ë…¸ì´ì¦ˆ í•„í„°ë§ (ë„ˆë¬´ ì§§ê±°ë‚˜ ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° ì œì™¸)
                if credit < 0 or credit > 5.0: continue
                if len(raw_name) < 2 or raw_name.isdigit(): continue

                ftype = classify_course_logic(raw_name, year, version, dept)
                parsed_data.append({"ê°•ì˜ëª…": raw_name, "í•™ì ": credit, "ì´ìˆ˜êµ¬ë¶„": ftype})
        return parsed_data
    except: return []

# --- 3. ì‚¬ì´ë“œë°” êµ¬ì„± (ìµœì¢… êµì • ë²„ì „) ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    if db:
        # 1ë‹¨ê³„: ë…„ë„(í•™ë²ˆ) ì„ íƒ (area_courses ì œì™¸í•œ ìµœìƒìœ„ í‚¤)
        years_list = sorted([k for k in db.keys() if k != "area_courses"], reverse=False)
        selected_year = st.selectbox("1ï¸âƒ£ ì…í•™ë…„ë„ ì„ íƒ", years_list, key="s_year_final")
        
        # 2ë‹¨ê³„: ì„¸ë¶€ íŒì • ê¸°ì¤€ ì„ íƒ (db[ë…„ë„]ì˜ í•˜ìœ„ í‚¤ë“¤)
        # ì˜ˆ: ['ì¡¸ì—…ìš”ê±´ ê¸°ì¤€', 'ì§„ë‹¨ì„¸í¬í•™ ì„ì‹œì‚­ì œ']
        if selected_year in db:
            versions_list = list(db[selected_year].keys())
            selected_version = st.selectbox("2ï¸âƒ£ ì„¸ë¶€ íŒì • ê¸°ì¤€", versions_list, key="s_version_final")
        else:
            selected_version = None

        # 3ë‹¨ê³„: ì „ê³µ ì„ íƒ (db[ë…„ë„][ë²„ì „]ì˜ í•˜ìœ„ í‚¤ë“¤)
        # ì˜ˆ: ['ì„ìƒë³‘ë¦¬í•™ê³¼']
        if selected_year and selected_version:
            # ì—¬ê¸°ì„œ db[selected_year][selected_version]ì„ ì½ì–´ì•¼ 
            # 'total_credits'ê°€ ì•„ë‹Œ 'ì„ìƒë³‘ë¦¬í•™ê³¼'ê°€ ì˜µì…˜ìœ¼ë¡œ ë‚˜ì˜µë‹ˆë‹¤.
            dept_list = list(db[selected_year][selected_version].keys())
            selected_dept = st.selectbox("3ï¸âƒ£ ì „ê³µ ì„ íƒ", dept_list, key="s_dept_final")
        else:
            selected_dept = "-"
            
    else:
        st.error("requirements.json ë¡œë“œ ì‹¤íŒ¨. íŒŒì¼ ê²½ë¡œì™€ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
        selected_year, selected_version, selected_dept = "2025", "-", "-"

    st.divider()
    
    # ìºì‹œ ë¹„ìš°ê¸° ë° ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ”„ ì„¤ì • ì´ˆê¸°í™” ë° ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear() # ìˆ˜ì •ëœ JSONì„ ìƒˆë¡œ ì½ì–´ì˜¤ê¸° ìœ„í•´ í•„ìˆ˜
        st.session_state.ocr_results = []
        st.rerun()
    if st.button("ğŸ› ë²„ê·¸ ì‹ ê³ "):
        show_bug_report_dialog(selected_year, selected_dept)

# --- 4. ë©”ì¸ UI ---
st.title("ğŸ“ ì—°ì„¸ëŒ€ ì„ìƒë³‘ë¦¬í•™ê³¼ ì¡¸ì—…ìš”ê±´ ì˜ˆë¹„ì§„ë‹¨")
st.info("ì—ë¸Œë¦¬íƒ€ì„ í•™ì ê³„ì‚°ê¸°(ì„±ì  í™”ë©´) ìº¡ì³ë³¸ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”. ì—¬ëŸ¬ ì¥ ì—…ë¡œë“œ ì‹œ ëª¨ë“  í•™ê¸°ë¥¼ í†µí•© ë¶„ì„í•©ë‹ˆë‹¤.")

tab1, tab2 = st.tabs(["ğŸ“¸ ì´ë¯¸ì§€ ë¶„ì„", "âœï¸ ê°•ì˜ ìˆ˜ì • ë° ìµœì¢… ì§„ë‹¨"])

with tab1:
    img_files = st.file_uploader("ì—ë¸Œë¦¬íƒ€ì„ í•™ì ê³„ì‚°ê¸° ìº¡ì³ ì´ë¯¸ì§€ (PNG, JPG)", type=['png','jpg','jpeg'], accept_multiple_files=True)
    if img_files and st.button("ğŸ” ì„±ì  ì´ë¯¸ì§€ì§€ ë¶„ì„ ì‹¤í–‰"):
        all_results = []

        with st.spinner(f"ì´ {len(img_files)}ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            for img in img_files: 
                result = ocr_image_parsing(img, selected_year, selected_version, selected_dept)
                all_results.extend(result)

            # ê°•ì˜ëª… ê¸°ì¤€ ì¤‘ë³µ ì œê±° ë° ì„¸ì…˜ ìƒíƒœ ì €ì¥
            if all_results:
                df_all = pd.DataFrame(all_results)

                # 1. "ì±„í”Œ"ì´ í¬í•¨ëœ í–‰ë“¤ë§Œ ë”°ë¡œ ì¶”ì¶œ (ì¤‘ë³µ ì œê±° ì œì™¸ ëŒ€ìƒ)
                # normalize_stringì„ ì‚¬ìš©í•˜ì—¬ 'ì±„í”Œ', 'ì±„í”Œ(1)' ë“±ì„ ëª¨ë‘ ì¡ìŠµë‹ˆë‹¤.
                is_chapel = df_all['ê°•ì˜ëª…'].apply(lambda x: "ì±„í”Œ" in x)
                df_chapel = df_all[is_chapel]

                # 2. ì±„í”Œì´ ì•„ë‹Œ ë‚˜ë¨¸ì§€ ê°•ì˜ë“¤ë§Œ ì¶”ì¶œí•˜ì—¬ ì¤‘ë³µ ì œê±° ìˆ˜í–‰
                df_others = df_all[~is_chapel].drop_duplicates(subset=['ê°•ì˜ëª…'])

                # 3. ë‘ ë°ì´í„°í”„ë ˆì„ì„ ë‹¤ì‹œ í•©ì¹˜ê¸°
                df_final = pd.concat([df_chapel, df_others], ignore_index=True)

                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.ocr_results = df_final.to_dict('records')
                st.success(f"ë¶„ì„ ì™„ë£Œ! ì´ {len(st.session_state.ocr_results)}ê°œì˜ ê°•ì˜ì„ ì¸ì‹í–ˆìŠµë‹ˆë‹¤. (ì±„í”Œ í¬í•¨)")                

with tab2:
    st.markdown("### ğŸ“ ìˆ˜ê°• ê°•ì˜ ê´€ë¦¬")

    # --- êµê³¼ê³¼ì • ì´ë¯¸ì§€ ì¶œë ¥ ë¡œì§ ì¶”ê°€ ---
    img_path = f"images/{selected_year}_{selected_dept}.png"

    try:
        guide_img = Image.open(img_path)
    
        # ì‚¬ì´ì¦ˆ ì¡°ì ˆ (ì´ì „ ê°€ì´ë“œ ì ìš©)
        target_width = 500
        width_percent = (target_width / float(guide_img.size[0]))
        target_height = int((float(guide_img.size[1]) * float(width_percent)))
        resized_img = guide_img.resize((target_width, target_height), Image.Resampling.LANCZOS)

        # [ìˆ˜ì •] í•™ë²ˆì— ë”°ë¥¸ ìº¡ì…˜ ë¶„ê¸° ì²˜ë¦¬
        # 2021ë…„ ë¯¸ë§Œì¸ ê²½ìš° ì•ˆë‚´ ë¬¸êµ¬ ì¶”ê°€
        if int(re.sub(r'[^0-9]', '', selected_year)) < 2021:
            img_caption = f"ğŸ“– {selected_year}í•™ë²ˆ ê°€ì´ë“œ (2021ë…„ë„ ìë£Œ ì„ì‹œ ì ìš©)"
        else:
            img_caption = f"ğŸ“– {selected_year}í•™ë²ˆ {selected_dept} êµê³¼ê³¼ì • ê°€ì´ë“œ"

        # ì´ë¯¸ì§€ ì¶œë ¥
        st.image(resized_img, caption=img_caption)

    except FileNotFoundError:
        st.caption(f"â„¹ï¸ {selected_year}í•™ë²ˆ ê°€ì´ë“œ ì´ë¯¸ì§€ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
    st.divider()
    st.caption("OCR ì¸ì‹ ê²°ê³¼(ê°•ì˜ëª…, í•™ì , ì´ìˆ˜êµ¬ë¶„ ë“±)ê°€ ì •í™•í•˜ì§€ ì•Šì„ ê²½ìš° ìˆ˜ë™ìœ¼ë¡œ ìˆ˜ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. í–‰ ì™¼ìª½(ì²´í¬ë°•ìŠ¤)ì„ í´ë¦­í•˜ì—¬ ì‚­ì œí•˜ê±°ë‚˜ í•˜ë‹¨ì—ì„œ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # ì—ë””í„°ìš© ë°ì´í„°í”„ë ˆì„ ìƒì„±
    df_editor = pd.DataFrame(st.session_state.ocr_results)
    if df_editor.empty:
        df_editor = pd.DataFrame(columns=["ê°•ì˜ëª…", "í•™ì ", "ì´ìˆ˜êµ¬ë¶„"])

    edited_df = st.data_editor(
        df_editor, num_rows="dynamic", use_container_width=True,
        column_config={
            "í•™ì ": st.column_config.NumberColumn("í•™ì ", step=0.5, format="%.1f"),
            "ì´ìˆ˜êµ¬ë¶„": st.column_config.SelectboxColumn("ì´ìˆ˜êµ¬ë¶„", options=[
                "ì „ê³µí•„ìˆ˜", "ì „ê³µì„ íƒ", "êµì–‘(ë¦¬ë”ì‹­)", "êµì–‘(ë¬¸í•™ê³¼ì˜ˆìˆ )", "êµì–‘(ì¸ê°„ê³¼ì—­ì‚¬)", 
                "êµì–‘(ì–¸ì–´ì™€í‘œí˜„)", "êµì–‘(ê°€ì¹˜ì™€ìœ¤ë¦¬)", "êµì–‘(êµ­ê°€ì™€ì‚¬íšŒ)", "êµì–‘(ì§€ì—­ê³¼ì„¸ê³„)", 
                "êµì–‘(ë…¼ë¦¬ì™€ìˆ˜ë¦¬)", "êµì–‘(ìì—°ê³¼ìš°ì£¼)", "êµì–‘(ìƒëª…ê³¼í™˜ê²½)", "êµì–‘(ì •ë³´ì™€ê¸°ìˆ )", 
                "êµì–‘(ì²´ìœ¡ê³¼ê±´ê°•)", "êµì–‘/ê¸°íƒ€"
            ])
        }, key="main_editor"
    )

    # --- 5. ìµœì¢… ë¶„ì„ ê²°ê³¼ í‘œì‹œ (ì‹¬í™”í•™ì  í¬í•¨) ---
    st.divider()
    if not edited_df.empty:
        final_courses = edited_df.to_dict('records')

        criteria = db[selected_year][selected_version][selected_dept]
        gen = criteria.get("general_education", {})
        known = criteria.get("known_courses", {})

        # 1. ê¸°ë³¸ í•™ì  ë³€ìˆ˜ ì´ˆê¸°í™”
        total_sum = 0.0
        maj_req = 0.0
        maj_sel = 0.0
        advanced_sum = 0.0
        detected_advanced = []

        # 2. [NEW] 3000~4000ë‹¨ìœ„(ì‹¬í™”) í•™ì  ê³„ì‚°
        adv_keywords_raw = known.get("advanced_keywords", [])
        norm_adv_keywords = sorted(list(set([normalize_string(kw) for kw in adv_keywords_raw])), key=len)

        # 2. ëª¨ë“  ê°•ì˜ë¥¼ í•œ ë²ˆì— ìˆœíšŒí•˜ë©° í•™ì  í•©ì‚° (ì¤‘ìš”!)
        for c in final_courses:
            c_name = str(c['ê°•ì˜ëª…']).strip()
            c_credit = float(c['í•™ì '])
            c_type = str(c['ì´ìˆ˜êµ¬ë¶„']).strip()
            norm_name = normalize_string(c_name)

            total_sum += c_credit

            # [ìˆ˜ì •] ì‚¬ìš©ìê°€ í…Œì´ë¸”ì—ì„œ ì„ íƒí•œ 'ì´ìˆ˜êµ¬ë¶„'ì„ ìµœìš°ì„ ìœ¼ë¡œ ë°˜ì˜
            if c_type == "ì „ê³µí•„ìˆ˜":
                maj_req += c_credit
            elif c_type == "ì „ê³µì„ íƒ":
                maj_sel += c_credit

            # ì‹¬í™” í•™ì  íŒì • (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            is_advanced_by_key = any(kw in norm_name for kw in norm_adv_keywords)
            is_major = "ì „ê³µ" in c_type
            basic_list = ["ì¸ì²´í•´ë¶€í•™", "ì˜í•™ìš©ì–´", "í•´ë¶€í•™", "ì„¸í¬ìƒë¬¼í•™", "ë³‘ë¦¬í•™", "ë¯¸ìƒë¬¼í•™", "ì¡°ì§í•™"]
            is_basic = any(basic == c_name for basic in basic_list)
            is_advanced_work = any(word in c_name for word in ["ì§„ë‹¨", "ì¢…í•©ì„¤ê³„", "ì„ìƒì‹¤ìŠµ"])

            if is_advanced_by_key or (is_major and not (is_basic and not is_advanced_work)):
                advanced_sum += c_credit
                detected_advanced.append(c_name)

        maj_total_sum = maj_req + maj_sel

        # 3. í•„ìˆ˜ ê³¼ëª© ì´ìˆ˜ ì—¬ë¶€ ì²´í¬ (ì´ìˆ˜êµ¬ë¶„ê¹Œì§€ í™•ì¸)
        req_fail = []
        
        all_course_names = [normalize_string(c['ê°•ì˜ëª…']) for c in final_courses] # ë¦¬ìŠ¤íŠ¸ ë¨¼ì € ì •ì˜
        all_names_text = " ".join(all_course_names) # ê·¸ ë‹¤ìŒ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°
        
        # ë¦¬ë”ì‹­ ì²´í¬
        leadership_count = len([c for c in final_courses if "ë¦¬ë”ì‹­" in str(c['ì´ìˆ˜êµ¬ë¶„']) or "RC" in normalize_string(c['ê°•ì˜ëª…'])])
        if leadership_count < 2:
            req_fail.append(f"ë¦¬ë”ì‹­(ê°œë°œ/ì‹¤ìŠµ) ({leadership_count}/2ê°•ì˜ ì´ìˆ˜)")

        career_design_keywords = ["ì§„ë¡œì§€ë„", "ì§„ë¡œì„¤ê³„"]
        has_career_design = any(any(kw in name for kw in career_design_keywords) for name in all_course_names)
        if not has_career_design:
            req_fail.append("RCì§„ë¡œì„¤ê³„ (ì„ìƒë³‘ë¦¬ì‚¬ì§„ë¡œì§€ë„)")

        # [3] RCê²½ë ¥ê°œë°œ ì²´í¬ (3ê°œ ì¤‘ 2ê°œ í•„ìˆ˜)
        # ëŒ€ìƒ: ì»¤ë¦¬ì–´ë””ìì¸, ì‚°ì—…ê³¼ê¸°ì—…ì˜ì´í•´, ê³µê³µê¸°ê´€ì˜ì´í•´
        career_dev_keywords = ["ì»¤ë¦¬ì–´ë””ìì¸", "ì‚°ì—…ê³¼ê¸°ì—…ì˜ì´í•´", "ê³µê³µê¸°ê´€ì˜ì´í•´"]
        # ì¤‘ë³µ ìˆ˜ê°•ì€ ì—†ë‹¤ê³  ê°€ì •í•˜ê³ , í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì„œë¡œ ë‹¤ë¥¸ ê°•ì˜ ìˆ˜ë¥¼ ì¹´ìš´íŠ¸
        dev_count = 0
        for kw in career_dev_keywords:
            if any(kw in name for name in all_course_names):
                dev_count += 1
    
        if dev_count < 2:
            req_fail.append(f"RCê²½ë ¥ê°œë°œ ({dev_count}/2ê°œ ì´ìˆ˜ ì¤‘)")

        # [4] ëŒ€í•™í•™ë¬¸ì˜ì„¸ê³„ ì²´í¬ (1ê°œ í•„ìˆ˜)
        if "ëŒ€í•™í•™ë¬¸ì˜ì„¸ê³„" not in all_names_text:
            req_fail.append("ëŒ€í•™í•™ë¬¸ì˜ì„¸ê³„")

        # [5] ê¸°íƒ€ JSON ì •ì˜ í•„ìˆ˜êµì–‘ ì²´í¬ (ì¤‘ë³µ ë¡œì§ í†µí•©)
        # gen.get("required_courses")ë¥¼ ìˆœíšŒí•˜ë©° ìœ„ì—ì„œ ê°œë³„ ì²´í¬í•œ í•­ëª©(ë¦¬ë”ì‹­, ì§„ë¡œê²½ë ¥, ëŒ€í•™í•™ë¬¸)ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ë§Œ ì²´í¬
        for item in gen.get("required_courses", []):
            item_name = item['name']
            # ì´ë¯¸ ìœ„ì—ì„œ ì •ë°€í•˜ê²Œ ì²´í¬í•œ í•­ëª©ì€ ê±´ë„ˆëœ€
            if item_name in ["ë¦¬ë”ì‹­", "ì§„ë¡œê²½ë ¥", "ëŒ€í•™í•™ë¬¸"]:
                continue
        
            is_satisfied = any(any(normalize_string(kw) in name for kw in item["keywords"]) for name in all_course_names)
            if not is_satisfied:
                req_fail.append(item_name)

        # [6] ì „ê³µí•„ìˆ˜ ê³¼ëª© ì²´í¬ (ì´ìˆ˜êµ¬ë¶„ í™•ì¸ í¬í•¨)
        # ì„ìƒë³‘ë¦¬í•™ê³¼ ì „ê³µí•„ìˆ˜(ì§„ë‹¨ì„¸í¬í•™ ë“±)ë¥¼ ì •í™•íˆ íŒì •í•©ë‹ˆë‹¤
        for mr_course in known.get("major_required", []):
            norm_mr = normalize_string(mr_course)
            # ê°•ì˜ëª…ì´ ë§¤ì¹­ë˜ë©´ì„œ ì‚¬ìš©ìê°€ 'ì „ê³µí•„ìˆ˜'ë¡œ ì„¤ì •í–ˆëŠ”ì§€ í™•ì¸
            is_passed = any(
                norm_mr in normalize_string(c['ê°•ì˜ëª…']) and c['ì´ìˆ˜êµ¬ë¶„'] == "ì „ê³µí•„ìˆ˜" 
                for c in final_courses
            )
            if not is_passed:
                req_fail.append(f"ì „ê³µí•„ìˆ˜({mr_course})")
    
        # ìµœì¢… íŒì • ë¡œì§
        pass_total = total_sum >= criteria['total_credits']
        pass_major_total = maj_total_sum >= criteria['major_total']
        pass_major_req = maj_req >= criteria['major_required']
        pass_advanced = advanced_sum >= criteria['advanced_course']
        pass_req_courses = len(req_fail) == 0

        is_all_pass = all([pass_total, pass_major_total, pass_major_req, pass_advanced, pass_req_courses])

        st.info("â„¹ï¸ ë³¸ ì§„ë‹¨ ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì´ë©°, ì •í™•í•œ ì¡¸ì—… ì—¬ë¶€ëŠ” í•™ê³¼ ì‚¬ë¬´ì‹¤ì„ í†µí•´ ìµœì¢…í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        st.header("ğŸ ì¡¸ì—… ìê²© ì˜ˆë¹„ì§„ë‹¨ ë¦¬í¬íŠ¸")
        if is_all_pass: 
            st.success("ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! ëª¨ë“  ì¡¸ì—… ìš”ê±´ì„ ì¶©ì¡±í–ˆìŠµë‹ˆë‹¤."); st.balloons()
        else: 
            st.error("âš ï¸ ì•„ì§ ì¶©ì¡±ë˜ì§€ ì•Šì€ ìš”ê±´ì´ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ëŒ€ì‹œë³´ë“œì™€ ë³´ì™„ ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”.")

        # --- ë©”ì‹œì§€ ì¶œë ¥ ìœ„ì¹˜ ---
        # âš ï¸ Metric ëŒ€ì‹œë³´ë“œë³´ë‹¤ ìœ„ì— ì¶œë ¥ë˜ë„ë¡ ìœ„ì¹˜ ì¡°ì •
        if detected_advanced:
            st.info(f"âœ… **ì‹¬í™” íŒì •ëœ ê°•ì˜:** {', '.join(detected_advanced)}")
        else:
            st.warning("âš ï¸ **ì‹¬í™”ë¡œ ì¸ì‹ëœ ê°•ì˜ì´ ì—†ìŠµë‹ˆë‹¤.** í…Œì´ë¸”ì˜ ê°•ì˜ëª…ì— 'ì„ìƒí™”í•™', 'ë¶„ìì§„ë‹¨' ë“±ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

        # ëŒ€ì‹œë³´ë“œ ë ˆì´ì•„ì›ƒ (4ì—´ êµ¬ì„±)
        m1, m2, m3, m4 = st.columns(4)
        m1.metric("ì´ ì·¨ë“í•™ì ", f"{int(total_sum)} / {criteria['total_credits']}", delta=int(total_sum - criteria['total_credits']))
        m2.metric("ì „ê³µ í•©ê³„", f"{int(maj_total_sum)} / {criteria['major_total']}")
        m3.metric("3~4000ë‹¨ìœ„(ì‹¬í™”ì „ê³µ)", f"{int(advanced_sum)} / {criteria['advanced_course']}", delta=int(advanced_sum - criteria['advanced_course']), delta_color="normal")
        m4.metric("ë¦¬ë”ì‹­(RCê°•ì˜)", f"{leadership_count} / 2")

        # ì„¸ë¶€ ë³´ì™„ ì‚¬í•­ ì•ˆë‚´
        if not is_all_pass:
            with st.expander("ğŸ› ï¸ ì„¸ë¶€ ë³´ì™„ í•„ìš” ì‚¬í•­", expanded=True):
                if not pass_major_req:
                    st.warning(f"ğŸ“ **ì „ê³µí•„ìˆ˜ í•™ì **ì´ {int(criteria['major_required'] - maj_req)}í•™ì  ë¶€ì¡±í•©ë‹ˆë‹¤.")
                if not pass_advanced:
                    st.warning(f"ğŸ“ **3000~4000ë‹¨ìœ„(ì‹¬í™”ì „) í•™ì **ì´ {int(criteria['advanced_course'] - advanced_sum)}í•™ì  ë¶€ì¡±í•©ë‹ˆë‹¤.")
                if req_fail:
                    st.error(f"ğŸ“ **ë¯¸ì´ìˆ˜ í•„ìˆ˜ ìš”ê±´:** {', '.join(req_fail)}")

        with st.expander("ğŸ“Š ìˆ˜ê°• ê°•ì˜ ìƒì„¸ í†µê³„"):
            st.dataframe(pd.DataFrame(final_courses), use_container_width=True)
    else:
        st.info("ì„±ì í‘œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

