import streamlit as st
import re
import pandas as pd
import json
import pytesseract
from PIL import Image, ImageOps, ImageEnhance
import numpy as np

# --- 0. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="ì—°ì„¸ëŒ€ ì¡¸ì—…ì˜ˆë¹„ì§„ë‹¨", page_icon="ğŸ“", layout="wide")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'ocr_results' not in st.session_state:
    st.session_state.ocr_results = []

# --- 1. ì¡¸ì—…ìš”ê±´ DB ë¡œë“œ ---
@st.cache_data
def load_requirements():
    try:
        with open('requirements.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

db = load_requirements()

# --- 2. í—¬í¼ í•¨ìˆ˜ ---
def normalize_string(s):
    if not isinstance(s, str): return ""
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ëŒ€ë¬¸ìí™” (ë§¤ì¹­ ì •í™•ë„ í–¥ìƒ)
    return re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', s).upper()

@st.dialog("ğŸ› ë²„ê·¸ ì‹ ê³  ë° ë¬¸ì˜")
def show_bug_report_dialog(year_key, dept):
    st.write("ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë‚˜ìš”? ì•„ë˜ ì •ë³´ë¥¼ ë³µì‚¬í•´ì„œ ë©”ì¼ì„ ë³´ë‚´ì£¼ì„¸ìš”.")
    st.divider()
    st.caption("1. ë°›ëŠ” ì‚¬ëŒ ì´ë©”ì¼")
    st.code("jaekwang1164@gmail.com", language="text")
    st.caption("2. ë©”ì¼ ì œëª©")
    st.code(f"[ì¡¸ì—…ì§„ë‹¨ê¸° ë²„ê·¸ì‹ ê³ ] {year_key} {dept}", language="text")
    st.caption("3. ë³¸ë¬¸ ë‚´ìš©")
    st.code("- ì˜¤ë¥˜ í˜„ìƒ:\n- ê¸°ëŒ€ ê²°ê³¼:\n- ì²¨ë¶€íŒŒì¼ ì—¬ë¶€(ì—íƒ€ ìº¡ì³ë³¸ ë“±):", language="text")

def classify_course_logic(course_name, year_key, dept):
    """ì´ë¯¸ì§€ ë¶„ì„ ì‹œ ì´ˆê¸° ë¶„ë¥˜ ë¡œì§"""
    norm_name = normalize_string(course_name)
    
    # 1. RC ë° ë¦¬ë”ì‹­ íŠ¹ë³„ ì²˜ë¦¬
    if "RC" in norm_name or "ë¦¬ë”ì‹­" in norm_name:
        return "êµì–‘(ë¦¬ë”ì‹­)"

    if year_key not in db or dept not in db[year_key]:
        return "êµì–‘/ê¸°íƒ€"
    
    dept_db = db[year_key][dept]
    known = dept_db.get("known_courses", {})
    
    # 2. ì „ê³µ í•„ìˆ˜/ì„ íƒ ì²´í¬
    for req in known.get("major_required", []):
        if normalize_string(req) in norm_name: return "ì „ê³µí•„ìˆ˜"
    for sel in known.get("major_elective", []):
        if normalize_string(sel) in norm_name: return "ì „ê³µì„ íƒ"
            
    # 3. êµì–‘ ì˜ì—­ ì²´í¬
    for area, courses in db.get("area_courses", {}).items():
        for c in courses:
            if normalize_string(c) in norm_name: return f"êµì–‘({area})"
                
    return "êµì–‘/ê¸°íƒ€"

def ocr_image_parsing(image_file, year_key, dept):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° OCR íŒŒì‹± (ì¸ì‹ë¥  ë° ì†ë„ ìµœì í™”)"""
    try:
        img = Image.open(image_file).convert('L')
        # í•´ìƒë„ ìµœì í™” (1500px ê¸°ì¤€)
        if img.width > 1500:
            ratio = 1500 / float(img.width)
            new_height = int(float(img.height) * ratio)
            img = img.resize((1500, new_height), Image.Resampling.LANCZOS)
            
        img = ImageEnhance.Sharpness(img).enhance(2.0)
        img = ImageOps.autocontrast(img)
        img = ImageEnhance.Contrast(img).enhance(2.5)
        
        # PSM 6: ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¸”ë¡ ê°€ì •, OEM 3: ê¸°ë³¸ ì—”ì§„
        custom_config = '--psm 6 --oem 3'
        text = pytesseract.image_to_string(img, lang='kor+eng', config=custom_config)
        
        parsed_data = []
        for line in text.split('\n'):
            # íŒ¨í„´: (ê°•ì˜ëª…) (í•™ì ) ìˆœì„œ
            match = re.search(r'^(.*?)\s+(\d+(?:\.\d+)?)(?:\s+.*)?$', line.strip())
            if match:
                raw_name = match.group(1).strip()
                try:
                    credit = float(match.group(2))
                except: continue
                
                # í•™ì  ì»·ì˜¤í”„ ë° ë…¸ì´ì¦ˆ í•„í„°ë§
                if credit <= 0 or credit > 5.0: continue
                if len(raw_name) < 2 or raw_name.isdigit(): continue
                
                ftype = classify_course_logic(raw_name, year_key, dept)
                parsed_data.append({"ê°•ì˜ëª…": raw_name, "í•™ì ": credit, "ì´ìˆ˜êµ¬ë¶„": ftype})
        return parsed_data
    except: return []

# --- 3. ì‚¬ì´ë“œë°” êµ¬ì„± ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    all_keys = [k for k in db.keys() if k != "area_courses"]
    if not all_keys:
        st.error("requirements.json ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # 1. ì…í•™ì—°ë„ ìˆ«ì ì¶”ì¶œ (ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬)
    years_only = sorted(list(set([re.sub(r'\(.*?\)', '', k) for k in all_keys])), reverse=True)
    selected_year_num = st.selectbox("ğŸ“… ì…í•™ë…„ë„ ì„ íƒ", years_only)

    # 2. ì¡¸ì—… ê¸°ì¤€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë§¤í•‘
    relevant_full_keys = [k for k in all_keys if k.startswith(selected_year_num)]
    
    def extract_version_text(full_key):
        match = re.search(r'\((.*?)\)', full_key)
        return match.group(1) if match else "ê¸°ë³¸ ê¸°ì¤€"
        
    version_map = {extract_version_text(k): k for k in relevant_full_keys}
    selected_version_text = st.selectbox("ğŸ“‹ ì¡¸ì—… íŒì • ê¸°ì¤€", list(version_map.keys()))
    selected_full_key = version_map[selected_version_text]
    
    # 3. ì „ê³µ ì„ íƒ
    dept_options = list(db[selected_full_key].keys()) if selected_full_key in db else ["-"]
    selected_dept = st.selectbox("ğŸ“ ì „ê³µ", dept_options)
    
    st.divider()
    if st.button("ğŸ”„ ëª¨ë“  ë°ì´í„° ì´ˆê¸°í™”"):
        st.session_state.ocr_results = []
        st.rerun()
    
    if st.button("ğŸ› ë²„ê·¸ ì‹ ê³ "):
        show_bug_report_dialog(selected_full_key, selected_dept)

# --- 4. ë©”ì¸ UI ---
st.title("ğŸ“ ì—°ì„¸ëŒ€ ì„ìƒë³‘ë¦¬í•™ê³¼ ì¡¸ì—…ìš”ê±´ ì˜ˆë¹„ì§„ë‹¨")
st.info("ì—ë¸Œë¦¬íƒ€ì„ í•™ì ê³„ì‚°ê¸° ìº¡ì³ë³¸ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

tab1, tab2 = st.tabs(["ğŸ“¸ ì´ë¯¸ì§€ ë¶„ì„", "âœï¸ ê°•ì˜ ìˆ˜ì • ë° ìµœì¢… ì§„ë‹¨"])

with tab1:
    img_files = st.file_uploader("ì—ë¸Œë¦¬íƒ€ì„ ì„±ì  ì´ë¯¸ì§€ ì—…ë¡œë“œ (PNG, JPG)", type=['png','jpg','jpeg'], accept_multiple_files=True)
    if img_files and st.button("ğŸ” ì„±ì  ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰"):
        all_results = []
        with st.spinner(f"{len(img_files)}ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ìˆœì°¨ ë¶„ì„ ì¤‘..."):
            for img in img_files: 
                result = ocr_image_parsing(img, selected_full_key, selected_dept)
                all_results.extend(result)
            
            if all_results:
                df_all = pd.DataFrame(all_results)
                # ì±„í”Œ ì¤‘ë³µ ìœ ì§€, ë‚˜ë¨¸ì§€ ê³¼ëª© ì¤‘ë³µ ì œê±°
                is_chapel = df_all['ê°•ì˜ëª…'].apply(lambda x: "ì±„í”Œ" in x)
                df_chapel = df_all[is_chapel]
                df_others = df_all[~is_chapel].drop_duplicates(subset=['ê°•ì˜ëª…'])
                df_final = pd.concat([df_chapel, df_others], ignore_index=True)
                
                st.session_state.ocr_results = df_final.to_dict('records')
                st.success(f"ë¶„ì„ ì™„ë£Œ! {len(st.session_state.ocr_results)}ê°œì˜ ê°•ì˜ë¥¼ ì¸ì‹í–ˆìŠµë‹ˆë‹¤. 'ê°•ì˜ ìˆ˜ì •' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")
                st.rerun()

with tab2:
    st.markdown("### ğŸ“ ìˆ˜ê°• ê°•ì˜ ê´€ë¦¬")
    
    # ê°€ì´ë“œ ì´ë¯¸ì§€ ì¶œë ¥
    img_path = f"images/{selected_full_key}_{selected_dept}.png"
    try:
        st.image(Image.open(img_path), caption=f"ğŸ“– {selected_full_key} ê°€ì´ë“œ", use_container_width=True)
    except FileNotFoundError:
        try:
            basic_path = f"images/{selected_year_num}_{selected_dept}.png"
            st.image(Image.open(basic_path), caption=f"ğŸ“– {selected_year_num} ê°€ì´ë“œ", use_container_width=True)
        except:
            st.caption("â„¹ï¸ í•´ë‹¹ ê¸°ì¤€ì˜ ê°€ì´ë“œ ì´ë¯¸ì§€ê°€ í´ë”ì— ì—†ìŠµë‹ˆë‹¤.")

    st.divider()
    df_editor = pd.DataFrame(st.session_state.ocr_results)
    if df_editor.empty:
        df_editor = pd.DataFrame(columns=["ê°•ì˜ëª…", "í•™ì ", "ì´ìˆ˜êµ¬ë¶„"])

    edited_df = st.data_editor(
        df_editor, num_rows="dynamic", use_container_width=True,
        column_config={
            "í•™ì ": st.column_config.NumberColumn("í•™ì ", step=0.5, format="%.1f"),
            "ì´ìˆ˜êµ¬ë¶„": st.column_config.SelectboxColumn("ì´ìˆ˜êµ¬ë¶„", options=[
                "ì „ê³µí•„ìˆ˜", "ì „ê³µì„ íƒ", "êµì–‘(ë¦¬ë”ì‹­)", "êµì–‘(ë¬¸í•™ê³¼ì˜ˆìˆ )", "êµì–‘(ì¸ê°„ê³¼ì—­ì‚¬)", 
                "êµì–‘(ì–¸ì–´ì™€í‘œí˜„)", "êµì–‘(ê°€ì¹˜ì™€ìœ¤ë¦¬)", "êµì–‘(êµ­ê°€ì™€ì‚¬íšŒ)", "êµì–‘(ì§€ì—­ê³¼ì„¸ê³„)", 
                "êµì–‘(ë…¼ë¦¬ì™€ìˆ˜ë¦¬)", "êµì–‘(ìì—°ê³¼ìš°ì£¼)", "êµì–‘(ìƒëª…ê³¼í™˜ê²½)", "êµì–‘(ì •ë³´ì™€ê¸°ìˆ )", 
                "êµì–‘(ì²´ìœ¡ê³¼ê±´ê°•)", "êµì–‘/ê¸°íƒ€"
            ])
        }, key="main_editor"
    )

    st.divider()
    final_courses = edited_df.to_dict('records')
    
    if final_courses:
        criteria = db[selected_full_key][selected_dept]
        gen = criteria.get("general_education", {})
        known = criteria.get("known_courses", {})
        
        # 1. í•™ì  ê³„ì‚° ë¡œì§
        total_sum = sum(c['í•™ì '] for c in final_courses)
        maj_req = sum(c['í•™ì '] for c in final_courses if c['ì´ìˆ˜êµ¬ë¶„'] == "ì „ê³µí•„ìˆ˜")
        maj_sel = sum(c['í•™ì '] for c in final_courses if c['ì´ìˆ˜êµ¬ë¶„'] == "ì „ê³µì„ íƒ")
        maj_total_sum = maj_req + maj_sel

        # 2. ì‹¬í™”ì „ê³µ(3~4ì²œë‹¨ìœ„) íŒì • ë¡œì§
        adv_keywords = [normalize_string(kw) for kw in known.get("advanced_keywords", [])]
        advanced_sum = 0.0
        detected_advanced = []

        for row in final_courses:
            c_name = str(row['ê°•ì˜ëª…']).strip()
            c_type = str(row['ì´ìˆ˜êµ¬ë¶„']).strip()
            c_credit = float(row['í•™ì '])
            norm_name = normalize_string(c_name)
            
            is_advanced_by_key = any(kw in norm_name for kw in adv_keywords)
            is_major = "ì „ê³µ" in c_type
            
            # ê¸°ì´ˆ ì „ê³µ ì œì™¸ ë¦¬ìŠ¤íŠ¸
            basic_list = ["ì¸ì²´í•´ë¶€í•™", "ì˜í•™ìš©ì–´", "í•´ë¶€í•™", "ì„¸í¬ìƒë¬¼í•™", "ë³‘ë¦¬í•™", "ë¯¸ìƒë¬¼í•™"]
            is_exactly_basic = any(c_name == basic for basic in basic_list) or (c_name == "ì¡°ì§í•™")
            
            # ì‹¬í™” íŒì • ë³´ê°• (ì§„ë‹¨/ì‹¤í—˜/ì¢…í•©ì„¤ê³„ ë“±)
            is_advanced_work = any(word in c_name for word in ["ì§„ë‹¨", "ì‹¤í—˜", "ì¢…í•©ì„¤ê³„", "íŠ¹ë¡ "])
            is_basic = is_exactly_basic and not is_advanced_work
            
            if is_advanced_by_key or (is_major and not is_basic):
                advanced_sum += c_credit
                detected_advanced.append(c_name)
            
        # 3. í•„ìˆ˜ ìš”ê±´ ì²´í¬ (ë¦¬ë”ì‹­, êµì–‘, ì „ê³µí•„ìˆ˜ ê°œë³„ ê³¼ëª©)
        leadership_count = len([c for c in final_courses if "ë¦¬ë”ì‹­" in str(c['ì´ìˆ˜êµ¬ë¶„']) or "RC" in normalize_string(c['ê°•ì˜ëª…'])])
        search_names_combined = " ".join([c['ê°•ì˜ëª…'] for c in final_courses])
        req_fail = []

        # 3-1. ì „ê³µí•„ìˆ˜ ê°œë³„ ê³¼ëª© ì´ìˆ˜ ì²´í¬ (ì‚­ì œ í…ŒìŠ¤íŠ¸ ëŒ€ì‘)
        for mr_course in known.get("major_required", []):
            if not any(normalize_string(mr_course) in normalize_string(c['ê°•ì˜ëª…']) for c in final_courses):
                req_fail.append(f"ì „ê³µí•„ìˆ˜({mr_course})")

        # 3-2. í•„ìˆ˜êµì–‘ ì˜ì—­ ë° ê³¼ëª© ì²´í¬
        for item in gen.get("required_courses", []):
            if item['name'] == "ë¦¬ë”ì‹­":
                if leadership_count < 2: req_fail.append("ë¦¬ë”ì‹­(RC) 2ê³¼ëª©")
            elif not any(normalize_string(kw) in normalize_string(search_names_combined) for kw in item["keywords"]):
                req_fail.append(item['name'])

        # 4. ìµœì¢… íŒì • ë¡œì§
        pass_total = total_sum >= criteria['total_credits']
        pass_major_total = maj_total_sum >= criteria['major_total']
        pass_major_req = maj_req >= criteria['major_required']
        pass_advanced = advanced_sum >= criteria['advanced_course']
        pass_req_courses = len(req_fail) == 0
        
        is_all_pass = all([pass_total, pass_major_total, pass_major_req, pass_advanced, pass_req_courses])

        # 5. ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥
        st.info("â„¹ï¸ ë³¸ ì§„ë‹¨ ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì´ë©°, ì •í™•í•œ ì¡¸ì—… ì—¬ë¶€ëŠ” í•™ê³¼ ì‚¬ë¬´ì‹¤ì„ í†µí•´ ìµœì¢…í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        st.header("ğŸ ì¡¸ì—… ìê²© ì˜ˆë¹„ì§„ë‹¨ ë¦¬í¬íŠ¸")
        
        if is_all_pass:
            st.success("ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! í˜„ì¬ ëª¨ë“  ìš”ê±´ì„ ì¶©ì¡±í–ˆìŠµë‹ˆë‹¤."); st.balloons()
        else:
            st.error("âš ï¸ ì•„ì§ ì¶©ì¡±ë˜ì§€ ì•Šì€ ìš”ê±´ì´ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")

        if detected_advanced:
            st.info(f"âœ… **ì‹¬í™” íŒì •ëœ ê°•ì˜:** {', '.join(set(detected_advanced))}")
        
        m1, m2, m3, m4 = st.columns(4)
        m1.metric("ì´ ì·¨ë“í•™ì ", f"{int(total_sum)} / {criteria['total_credits']}", delta=int(total_sum - criteria['total_credits']))
        m2.metric("ì „ê³µ í•©ê³„", f"{int(maj_total_sum)} / {criteria['major_total']}")
        m3.metric("ì‹¬í™”ì „ê³µ", f"{int(advanced_sum)} / {criteria['advanced_course']}")
        m4.metric("ë¦¬ë”ì‹­(RC)", f"{leadership_count} / 2")

        if not is_all_pass:
            with st.expander("ğŸ› ï¸ ì„¸ë¶€ ë³´ì™„ í•„ìš” ì‚¬í•­", expanded=True):
                if not pass_major_req:
                    st.warning(f"ğŸ“ **ì „ê³µí•„ìˆ˜ í•™ì **ì´ {int(criteria['major_required'] - maj_req)}í•™ì  ë¶€ì¡±í•©ë‹ˆë‹¤.")
                if not pass_advanced:
                    st.warning(f"ğŸ“ **ì‹¬í™”ì „ê³µ í•™ì **ì´ {int(criteria['advanced_course'] - advanced_sum)}í•™ì  ë¶€ì¡±í•©ë‹ˆë‹¤.")
                if req_fail:
                    st.error(f"ğŸ“ **ë¯¸ì´ìˆ˜ í•„ìˆ˜ ìš”ê±´:** {', '.join(req_fail)}")
        
        with st.expander("ğŸ“Š ìˆ˜ê°• ê°•ì˜ ìƒì„¸ í†µê³„"):
            st.dataframe(pd.DataFrame(final_courses), use_container_width=True)
    else:
        st.info("ì„±ì í‘œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
