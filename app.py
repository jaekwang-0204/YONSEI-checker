import streamlit as st
import pdfplumber
import re
import pandas as pd
import json
import pytesseract
from PIL import Image, ImageOps, ImageEnhance
import numpy as np

# Tesseract ê²½ë¡œ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

st.set_page_config(page_title="ì¡¸ì—…ìš”ê±´ ì§„ë‹¨ê¸° (Ultimate)", page_icon="ğŸ“", layout="wide")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'ocr_results' not in st.session_state:
    st.session_state.ocr_results = [] # OCR ê²°ê³¼ ì €ì¥ìš©

# --- 1. DB ë¡œë“œ ---
@st.cache_data
def load_requirements():
    try:
        with open('requirements.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

db = load_requirements()

# --- 2. í—¬í¼ í•¨ìˆ˜ ---
def normalize_string(s):
    if not isinstance(s, str): return ""
    return re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', s)

def clean_ocr_line(line):
    # ë…¸ì´ì¦ˆ ì œê±°
    line = re.sub(r'[~@#$%\^&*_\-=|;:"<>,.?/\[\]\{\}]', ' ', line)
    return line.strip()

def classify_course_keyword(course_name, year, dept):
    """í‚¤ì›Œë“œ í¬í•¨ ê¸°ë°˜ ë¶„ë¥˜"""
    if year not in db or dept not in db[year]:
        return "êµì–‘"
    
    known = db[year][dept].get("known_courses", {})
    norm_input = normalize_string(course_name)
    
    # 1. ì „ê³µ í•„ìˆ˜
    for req in known.get("major_required", []):
        if normalize_string(req) in norm_input:
            return "ì „ê³µí•„ìˆ˜"
            
    # 2. ì „ê³µ ì„ íƒ
    for sel in known.get("major_elective", []):
        if normalize_string(sel) in norm_input:
            return "ì „ê³µì„ íƒ"
            
    # 3. êµì–‘ ì˜ì—­ (JSONì˜ area_courses í™œìš©)
    for area, courses in db.get("area_courses", {}).items():
        for c in courses:
            if normalize_string(c) in norm_input:
                return f"êµì–‘({area})"
                
    return "êµì–‘"

def ocr_image_parsing(image_file, year, dept):
    """ì´ë¯¸ì§€ OCR ë° íŒŒì‹± (ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)"""
    try:
        img = Image.open(image_file).convert('L')
        img = ImageOps.autocontrast(img)
        img = ImageEnhance.Contrast(img).enhance(2.0)
        
        text = pytesseract.image_to_string(img, lang='kor+eng', config='--psm 6')
        
        parsed_data = []
        lines = text.split('\n')
        start_parsing = False
        
        for line in lines:
            line = clean_ocr_line(line)
            if not line: continue
            
            # í—¤ë” ê°ì§€
            if not start_parsing:
                if any(k in line for k in ["ê³¼ëª©ëª…", "í•™ì ", "ì„±ì ", "ì „ê³µ", "ë“±ê¸‰", "ì´ìˆ˜"]):
                    start_parsing = True
                continue
            
            # ë…¸ì´ì¦ˆ ì¤„ ê±´ë„ˆë›°ê¸°
            if any(k in line for k in ["í‰ì ", "ì·¨ë“", "ì´ì ", "ì‹ ì²­", "ë…„", "í•™ê¸°", "KT", "SKT"]):
                continue

            # íŒ¨í„´: (ê³¼ëª©ëª…) ... (í•™ì  ìˆ«ì: 0.5 ~ 9.0 í—ˆìš©)
            # ìˆ˜ì •ëœ ì •ê·œì‹: 0.5ë„ ì¡ì„ ìˆ˜ ìˆê²Œ (\d+(?:\.\d+)?) ì‚¬ìš©
            match = re.search(r'^(.*?)\s+(\d+(?:\.\d+)?)(?:\s+.*)?$', line)
            
            if match:
                raw_name = match.group(1).strip()
                credit = float(match.group(2))
                
                # [ê°•ë ¥ í•„í„°] ë…¸ì´ì¦ˆ ì œê±°
                # 1. ì´ë¦„ì´ ë„ˆë¬´ ì§§ê±°ë‚˜(1ê¸€ì), ìˆ«ìë¡œë§Œ êµ¬ì„±ë¨
                if len(raw_name) < 2 or raw_name.isdigit(): continue
                # 2. í•œê¸€/ì˜ì–´ê°€ ì—†ëŠ” íŠ¹ìˆ˜ë¬¸ì ë©ì–´ë¦¬
                if not re.search(r'[ê°€-í£a-zA-Z]', raw_name): continue
                # 3. ì„±ì (A, B, P)ì´ë‚˜ ì¡ìŒì´ ì´ë¦„ìœ¼ë¡œ ì¸ì‹ëœ ê²½ìš° ì œì™¸
                noise_keywords = ["At", "Bt", "Ap", "Ss", "BO", "Bo", "Pass", "P", "F", "NP"]
                if raw_name in noise_keywords: continue
                # 4. ì´ë¦„ì´ 3ê¸€ì ì´í•˜ ì˜ì–´ì¸ë° ì†Œë¬¸ìê°€ ì„ì—¬ìˆìœ¼ë©´ ì¡ìŒì¼ í™•ë¥  ë†’ìŒ (ì˜ˆ: "At a")
                if len(raw_name) <= 3 and re.search(r'[a-z]', raw_name): continue

                # ë¶„ë¥˜
                ftype = classify_course_keyword(raw_name, year, dept)
                
                parsed_data.append({
                    "ê³¼ëª©ëª…": raw_name,
                    "í•™ì ": credit,
                    "ì´ìˆ˜êµ¬ë¶„": ftype
                })
                    
        return text, parsed_data
    except Exception as e:
        return f"Error: {e}", []

def filter_failed_courses(full_text):
    lines = full_text.split('\n')
    filtered = []
    for line in lines:
        if re.search(r'\sF\s|\sF$|\sNP\s|\sNP$', line): continue
        filtered.append(line)
    return "\n".join(filtered)

@st.dialog("ğŸ› ë²„ê·¸ ì‹ ê³ ")
def show_bug_report(year, dept):
    st.write("ì˜¤ë¥˜ ë‚´ìš©ì„ ë³µì‚¬í•´ì„œ ë©”ì¼ì„ ë³´ë‚´ì£¼ì„¸ìš”.")
    st.code(f"ë°›ëŠ”ì‚¬ëŒ: jaekwang1164@gmail.com\nì œëª©: [ë²„ê·¸] {year} {dept}")

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    years = sorted([k for k in db.keys() if k != "area_courses"]) if db else ["2022"]
    selected_year = st.selectbox("ì…í•™ë…„ë„", years)
    depts = list(db[selected_year].keys()) if selected_year in db else ["-"]
    selected_dept = st.selectbox("ì „ê³µ", depts)
    
    st.divider()
    st.info("ğŸ’¡ íŒ: 'ê³¼ëª© ìˆ˜ì •/ì¶”ê°€' íƒ­ì—ì„œ ì¸ì‹ëœ ê³¼ëª©ì„ ì—‘ì…€ì²˜ëŸ¼ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    if st.button("ğŸ”„ ì´ˆê¸°í™”"):
        st.session_state.ocr_results = []
        st.rerun()

    st.divider()
    if st.button("ğŸ“§ ì˜¤ë¥˜ ì‹ ê³ "): show_bug_report(selected_year, selected_dept)

# --- ë©”ì¸ í™”ë©´ ---
st.title("ğŸ“ ì—°ì„¸ëŒ€ ì¡¸ì—…ìš”ê±´ ì§„ë‹¨ê¸°")

# íƒ­ êµ¬ì„±
tab1, tab2, tab3 = st.tabs(["ğŸ“„ PDF ì—…ë¡œë“œ", "ğŸ“¸ ì´ë¯¸ì§€(ìº¡ì³)", "âœï¸ ê³¼ëª© ìˆ˜ì •/ì¶”ê°€ (í•„ìˆ˜ í™•ì¸)"])
extracted_text_pdf = ""

# 1. PDF íƒ­
with tab1:
    pdf_file = st.file_uploader("PDF ì„±ì í‘œ", type="pdf")
    if pdf_file:
        with pdfplumber.open(pdf_file) as pdf:
            for p in pdf.pages: extracted_text_pdf += (p.extract_text() or "") + "\n"

# 2. ì´ë¯¸ì§€ íƒ­ (OCR)
with tab2:
    st.info("ì—ë¸Œë¦¬íƒ€ì„/í¬í„¸ ì„±ì  ìº¡ì³ (ì—¬ëŸ¬ ì¥ ê°€ëŠ¥)")
    img_files = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼", type=['png','jpg'], accept_multiple_files=True)
    
    if img_files:
        # ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ë©´ OCR ì‹¤í–‰ (ë²„íŠ¼ ì—†ì´ ìë™ ì‹¤í–‰í•˜ë˜ ì¤‘ë³µ ë°©ì§€ í•„ìš”)
        # ì—¬ê¸°ì„œëŠ” ë§¤ë²ˆ ì‹¤í–‰ë˜ì§€ ì•Šë„ë¡ ë²„íŠ¼ìœ¼ë¡œ ì œì–´í•˜ê±°ë‚˜, ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ê´€ë¦¬
        if st.button("ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰ (í´ë¦­)"):
            with st.spinner("ì´ë¯¸ì§€ ì •ë°€ ë¶„ì„ ì¤‘..."):
                temp_results = []
                for img in img_files:
                    _, parsed = ocr_image_parsing(img, selected_year, selected_dept)
                    temp_results.extend(parsed)
                
                # ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€ ë¡œì§ì€ ì—ë””í„°ì—ì„œ ì‚¬ìš©ìê°€ ë³´ê³  ì‚­ì œí•˜ê²Œ ìœ ë„)
                st.session_state.ocr_results = temp_results
                st.success(f"{len(temp_results)}ê°œ ê³¼ëª© ì¸ì‹ ì™„ë£Œ! 'ê³¼ëª© ìˆ˜ì •/ì¶”ê°€' íƒ­ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")

# 3. ë°ì´í„° ì—ë””í„° íƒ­ (í•µì‹¬ ê¸°ëŠ¥)
with tab3:
    st.markdown("### ğŸ“ ìˆ˜ê°• ê³¼ëª© ê´€ë¦¬")
    st.caption("ì´ë¯¸ì§€ ì¸ì‹ ê²°ê³¼ê°€ ì •í™•í•˜ì§€ ì•Šë‹¤ë©´ ì—¬ê¸°ì„œ ì§ì ‘ ìˆ˜ì •, ì¶”ê°€, ì‚­ì œí•˜ì„¸ìš”. **ì´ ë°ì´í„°ë¡œ ìµœì¢… ì§„ë‹¨í•©ë‹ˆë‹¤.**")
    
    # ë°ì´í„°í”„ë ˆì„ ìƒì„± (ì´ˆê¸° ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ í”„ë ˆì„)
    if st.session_state.ocr_results:
        df_input = pd.DataFrame(st.session_state.ocr_results)
    else:
        df_input = pd.DataFrame(columns=["ê³¼ëª©ëª…", "í•™ì ", "ì´ìˆ˜êµ¬ë¶„"])

    # st.data_editorë¡œ í¸ì§‘ ê°€ëŠ¥í•œ í…Œì´ë¸” ìƒì„±
    edited_df = st.data_editor(
        df_input,
        num_rows="dynamic", # í–‰ ì¶”ê°€/ì‚­ì œ ê°€ëŠ¥
        use_container_width=
